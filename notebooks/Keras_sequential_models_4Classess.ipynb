{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import collections\n",
    "import pickle\n",
    "import re\n",
    "import random\n",
    "import sys\n",
    "import os \n",
    "import time\n",
    "\n",
    "import gensim\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from gensim.models.fasttext import FastText\n",
    "from gensim.models import word2vec\n",
    "\n",
    "from sklearn.model_selection import train_test_split,cross_val_score, cross_val_predict, KFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix,precision_recall_fscore_support\n",
    "from sklearn import svm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "from numpy import cumsum\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "# from tensorflow import keras as K\n",
    "from keras import initializers\n",
    "from keras.models import Sequential,Model,load_model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dropout, Activation, Flatten, \\\n",
    "    Embedding, Convolution1D, MaxPooling1D, AveragePooling1D, \\\n",
    "    Input, Dense, merge, Add,TimeDistributed, Bidirectional,SpatialDropout1D, \\\n",
    "    Concatenate, concatenate, multiply, Lambda, dot, Layer\n",
    "from keras.layers.recurrent import LSTM, GRU, SimpleRNN\n",
    "from keras.regularizers import l2, l1_l2\n",
    "from keras.constraints import maxnorm\n",
    "from keras import callbacks\n",
    "from keras.utils import generic_utils,plot_model\n",
    "from keras.optimizers import Adadelta,Adam\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "# from keras.engine.topology import Layer\n",
    "\n",
    "\n",
    "import matplotlib.image  as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "import re\n",
    "import os\n",
    "from pathlib import Path\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import gensim.downloader as gensimapi\n",
    "from collections import Counter, defaultdict\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Backup\r\n",
      "'Cross Lingual Aspect Based Sentiment Analysis- Part 1.ipynb'\r\n",
      "'Cross Lingual Aspect Based Sentiment Analysis- Part 2.ipynb'\r\n",
      " Keras_ML_models.ipynb\r\n",
      " Keras_sequential_models_3_classess.ipynb\r\n",
      " Keras_sequential_models.ipynb\r\n",
      "'Multilingual  semeval  dataset creation.ipynb'\r\n",
      " results\r\n",
      "'Tatoeba Similarity Search.ipynb'\r\n",
      " Twitter_Data.ipynb\r\n",
      " utils\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_folder = \"../../../corpus/new/preprocess_from_isuru/\"\n",
    "# lankadeepa_data_path = data_folder + 'lankadeepa_tagged_comments.csv'\n",
    "# gossip_lanka_data_path = data_folder + 'gossip_lanka_tagged_comments.csv'\n",
    "\n",
    "# lankadeepa_data = pd.read_csv(lankadeepa_data_path)[:9059]\n",
    "# gossipLanka_data = pd.read_csv(gossip_lanka_data_path)\n",
    "# gossipLanka_data = gossipLanka_data.drop(columns=['Unnamed: 3'])\n",
    "\n",
    "# sinhala_data = pd.concat([lankadeepa_data,gossipLanka_data], ignore_index=True)\n",
    "# sinhala_data.to_csv(\"../data/sinhala_comments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aspects_ungrp = pd.read_csv('../data/Train_english_restaurants_ungrp.csv')\n",
    "val_aspects_ungrp2 = pd.read_csv('../data/Valid_english_restaurants_ungrp.csv')\n",
    "du_aspects_ungrp2  = pd.read_csv('../data/Dutch_restaurants_ungrp.csv')\n",
    "sp_aspects_ungrp2  = pd.read_csv('../data/Spanish_english_restaurants_ungrp.csv')\n",
    "\n",
    "sinhala_comments  = pd.read_csv('../data/sinhala_comments.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sinhala_comments = sinhala_comments.loc[sinhala_comments['label'].isin([2, 3, 4,5])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2 7665]\n",
      " [   3 2403]\n",
      " [   4 3080]\n",
      " [   5 1911]]\n"
     ]
    }
   ],
   "source": [
    "(unique, counts) = np.unique(sinhala_comments[\"label\"].values, return_counts = True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aspects_ungrp[['text']].to_csv('../data/processed/en_resturant.csv' , header = None , index = None , mode = 'w')\n",
    "val_aspects_ungrp2[['text']].to_csv('../data/processed/en_val.csv' , header = None , index = None , mode = 'w')\n",
    "du_aspects_ungrp2[['text']].to_csv('../data/processed/nl_resturant.csv' , header = None , index = None , mode = 'w')\n",
    "sp_aspects_ungrp2[['text']].to_csv('../data/processed/es_resturant.csv' , header = None , index = None , mode = 'w')\n",
    "\n",
    "sinhala_comments[['comment']].to_csv('../data/processed/sinhala_comments.csv' , header = None , index = None , mode = 'w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LASER_PATH = \"/home/lahiru/Projects/FYP/LASER/LASER\"\n",
    "sys.path.insert(0, LASER_PATH + '/source/lib')\n",
    "sys.path.insert(1, LASER_PATH + '/source')\n",
    "\n",
    "DATA_PATH = Path(\"../data/processed/\")\n",
    "CACHE_PATH = Path(\"../cache2/\")\n",
    "CACHE_PATH.mkdir(exist_ok=True)\n",
    "MODEL_PATH = Path(LASER_PATH + \"/models\")\n",
    "\n",
    "os.environ[\"LASER\"] = LASER_PATH \n",
    "SPACE_NORMALIZER = re.compile(\"\\s+\")\n",
    "Batch = namedtuple('Batch', 'srcs tokens lengths')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from indexing import IndexLoad, IndexTextOpen, IndexTextQuery, IndexSearchKNN, IndexCreate, IndexSearchMultiple\n",
    "from embed import SentenceEncoder, EncodeLoad, EncodeFile\n",
    "from text_processing import Token, BPEfastApply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Tokenizer: en_resturant.csv exists already\n",
      " - Tokenizer: nl_resturant.csv exists already\n",
      " - Tokenizer: es_resturant.csv exists already\n",
      " - Tokenizer: en_val.csv exists already\n"
     ]
    }
   ],
   "source": [
    "encoder = SentenceEncoder(\n",
    "    str(MODEL_PATH / \"bilstm.93langs.2018-12-26.pt\"),\n",
    "    max_sentences=None,\n",
    "    max_tokens=10000,\n",
    "    cpu=False)\n",
    "#original : cpu = False\n",
    "\n",
    "bpe_codes = str(MODEL_PATH / \"93langs.fcodes\")\n",
    "\n",
    "for lang in (\"en\" ,\"nl\", 'es'): \n",
    "    Token(\n",
    "        str(DATA_PATH / f\"{lang}_resturant.csv\"), ##english_resturant.txt\n",
    "        str(CACHE_PATH / f\"{lang}_resturant.csv\"),\n",
    "        lang=lang,\n",
    "        romanize=False,\n",
    "        lower_case=True, gzip=False,\n",
    "        verbose=True)\n",
    "    BPEfastApply(\n",
    "        str(CACHE_PATH / f\"{lang}_resturant.csv\"),\n",
    "        str(CACHE_PATH / f\"{lang}_resturant.bpe\"),\n",
    "        bpe_codes,\n",
    "        verbose=True, over_write=True)\n",
    "    EncodeFile(\n",
    "        encoder,\n",
    "        str(CACHE_PATH / f\"{lang}_resturant.bpe\"),\n",
    "        str(CACHE_PATH / f\"{lang}_resturant.enc\"),\n",
    "        verbose=True, over_write=True)    \n",
    "    \n",
    "    \n",
    "Token(\n",
    "    str(DATA_PATH / f\"en_val.csv\"), ##english_resturant.txt\n",
    "    str(CACHE_PATH / f\"en_val.csv\"),\n",
    "    lang=lang,\n",
    "    romanize=False,\n",
    "    lower_case=True, gzip=False,\n",
    "    verbose=True)\n",
    "BPEfastApply(\n",
    "    str(CACHE_PATH / f\"en_val.csv\"),\n",
    "    str(CACHE_PATH / f\"en_val.bpe\"),\n",
    "    bpe_codes,\n",
    "    verbose=True, over_write=True)\n",
    "EncodeFile(\n",
    "    encoder,\n",
    "    str(CACHE_PATH / f\"en_val.bpe\"),\n",
    "    str(CACHE_PATH / f\"en_val.enc\"),\n",
    "    verbose=True, over_write=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Tokenizer: sinhala_comments.csv exists already\n"
     ]
    }
   ],
   "source": [
    "Token(\n",
    "    str(DATA_PATH / f\"sinhala_comments.csv\"), ##english_resturant.txt\n",
    "    str(CACHE_PATH / f\"sinhala_comments.csv\"),\n",
    "    lang=\"sin\",\n",
    "    romanize=False,\n",
    "    lower_case=True, gzip=False,\n",
    "    verbose=True)\n",
    "BPEfastApply(\n",
    "    str(CACHE_PATH / f\"sinhala_comments.csv\"),\n",
    "    str(CACHE_PATH / f\"sinhala_comments.bpe\"),\n",
    "    bpe_codes,\n",
    "    verbose=True, over_write=True)\n",
    "EncodeFile(\n",
    "    encoder,\n",
    "    str(CACHE_PATH / f\"sinhala_comments.bpe\"),\n",
    "    str(CACHE_PATH / f\"sinhala_comments.enc\"),\n",
    "    verbose=True, over_write=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "LASER_PATH = \"/home/lahiru/Projects/FYP/LASER/LASER\"\n",
    "sys.path.insert(0, LASER_PATH + '/source/lib')\n",
    "sys.path.insert(1, LASER_PATH + '/source')\n",
    "\n",
    "DATA_PATH = Path(\"../data/processed/\")\n",
    "CACHE_PATH = Path(\"../cache2/\")\n",
    "CACHE_PATH.mkdir(exist_ok=True)\n",
    "MODEL_PATH = Path(LASER_PATH + \"/models\")\n",
    "\n",
    "os.environ[\"LASER\"] = LASER_PATH \n",
    "SPACE_NORMALIZER = re.compile(\"\\s+\")\n",
    "Batch = namedtuple('Batch', 'srcs tokens lengths')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - embedding: ../cache2/en_resturant.enc 1656 examples of dim 1024\n",
      " - creating FAISS index\n",
      " - embedding: ../cache2/en_val.enc 283 examples of dim 1024\n",
      " - creating FAISS index\n",
      " - embedding: ../cache2/nl_resturant.enc 960 examples of dim 1024\n",
      " - creating FAISS index\n",
      " - embedding: ../cache2/es_resturant.enc 1416 examples of dim 1024\n",
      " - creating FAISS index\n",
      " - embedding: ../cache2/sinhala_comments.enc 15059 examples of dim 1024\n",
      " - creating FAISS index\n"
     ]
    }
   ],
   "source": [
    "train_en, index_tr_en = IndexCreate(\n",
    "    str(CACHE_PATH / \"en_resturant.enc\"), 'FlatL2', verbose=True, save_index=False)\n",
    "val_en, index_val_en = IndexCreate(\n",
    "    str(CACHE_PATH / \"en_val.enc\"), 'FlatL2', verbose=True, save_index=False)\n",
    "\n",
    "data_du, index_du = IndexCreate(\n",
    "    str(CACHE_PATH / \"nl_resturant.enc\"), 'FlatL2', verbose=True, save_index=False)\n",
    "data_spanish, index_spanish = IndexCreate(\n",
    "    str(CACHE_PATH / \"es_resturant.enc\"), 'FlatL2', verbose=True, save_index=False)\n",
    "\n",
    "data_sinhala, index_sinhala = IndexCreate(\n",
    "    str(CACHE_PATH / \"sinhala_comments.enc\"), 'FlatL2', verbose=True, save_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_target(x):\n",
    "    if x=='positive':\n",
    "        return 2\n",
    "    elif x =='negative':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0 \n",
    "    \n",
    "def change_target_sinala(x):\n",
    "    if x== 4:\n",
    "        return 2\n",
    "    elif x == 2:\n",
    "        return 1\n",
    "    elif x == 3:\n",
    "        return 0 \n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "train_aspects_ungrp['polarities'] = train_aspects_ungrp['polarities'].apply(lambda x: change_target(x))\n",
    "val_aspects_ungrp2['polarities'] = val_aspects_ungrp2['polarities'].apply(lambda x: change_target(x))\n",
    "sp_aspects_ungrp2['polarities'] = sp_aspects_ungrp2['polarities'].apply(lambda x: change_target(x))\n",
    "du_aspects_ungrp2['polarities'] = du_aspects_ungrp2['polarities'].apply(lambda x: change_target(x))\n",
    "\n",
    "sinhala_comments['label'] = sinhala_comments['label'].apply(lambda x: change_target_sinala(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1656,), (283,), (960,), (1416,), (15059,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "tr_eng =  train_aspects_ungrp['polarities'].values\n",
    "val_eng =val_aspects_ungrp2['polarities'].values  \n",
    "y_du  = du_aspects_ungrp2['polarities'].values\n",
    "y_spainish  = sp_aspects_ungrp2['polarities'].values\n",
    "\n",
    "y_sinhala  = sinhala_comments['label'].values\n",
    "tr_eng.shape , val_eng.shape , y_du.shape , y_spainish.shape, y_sinhala.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0 2403]\n",
      " [   1 7665]\n",
      " [   2 3080]\n",
      " [   3 1911]]\n"
     ]
    }
   ],
   "source": [
    "(unique, counts) = np.unique(y_sinhala, return_counts = True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_eng = pd.get_dummies(tr_eng).values\n",
    "val_eng = pd.get_dummies(val_eng).values\n",
    "y_du = pd.get_dummies(y_du).values\n",
    "y_spainish = pd.get_dummies(y_spainish).values\n",
    "y_sinhala = pd.get_dummies(y_sinhala).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0], dtype=uint8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sinhala[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "std_scale = StandardScaler().fit(train_en)\n",
    "train_std = std_scale.transform(train_en) \n",
    "val_std = std_scale.transform(val_en)\n",
    "dutch_std = std_scale.transform(data_du)\n",
    "spanish_std = std_scale.transform(data_spanish)\n",
    "sinhala_std = std_scale.transform(data_sinhala)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1656, 1024)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = 64\n",
    "features = int(len(train_std[0]))//64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_std = train_std.reshape(len(train_std), time_steps, features)\n",
    "sinhala_std = sinhala_std.reshape(len(sinhala_std), time_steps, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1656, 64, 16)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN_model():\n",
    "    main_input = Input(shape=(time_steps,features ), dtype='float', name='main_input')\n",
    "#     embedding  = Embedding(MAX_FEATURES, EMBEDDING_SIZE\n",
    "#               , input_length=MAX_LEN,\n",
    "#               name='embedding' ,trainable=False)(main_input)\n",
    "\n",
    "#     embedding = Dropout(DROPOUT_VALUE_1)(main_input)\n",
    "\n",
    "    x = RNN(HIDDEN_DIMS)(main_input)\n",
    "\n",
    "    x = Dense(HIDDEN_DIMS, activation='relu', init='he_normal', \n",
    "              W_constraint = maxnorm(3), b_constraint=maxnorm(3),\n",
    "              name='mlp')(x)\n",
    "\n",
    "    x = Dropout(DROPOUT_VALUE_2, name='drop')(x)\n",
    "\n",
    "    output = Dense(4, init='he_normal',\n",
    "                   activation='softmax', name='output')(x)\n",
    "\n",
    "    model = Model(input=main_input, output=output ,name=\"RNN_model\")\n",
    "\n",
    "    model.compile(loss={'output':'categorical_crossentropy'},\n",
    "              optimizer=Adadelta(lr=0.95, epsilon=1e-06),\n",
    "              metrics=[\"accuracy\",\n",
    "                       keras.metrics.Precision(),\n",
    "                        keras.metrics.Recall(),\n",
    "                       f1])\n",
    "    \n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "# def simple_model():\n",
    "#     model = tf.keras.Sequential()\n",
    "#     model.add(tf.keras.layers.Dense(512))\n",
    "#     model.add(tf.keras.layers.Dense(256))\n",
    "#     model.add(tf.keras.layers.Dense(3))\n",
    "#     model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "#     # This builds the model for the first time:\n",
    "    \n",
    "#     return model\n",
    "\n",
    "# def simple_model2():\n",
    "    \n",
    "#     model = Sequential()\n",
    "#     model.add(LSTM(32, input_shape=(1024, 1024)))\n",
    "#     model.add(Dense(3))\n",
    "#     print(model.summary())\n",
    "#     model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "#     return model\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_Model(model,X_train, y_train, val_data=None , cross_validation = False):\n",
    "    print('Training and Testing...')\n",
    "    es = EarlyStopping(monitor='val_f1', mode='max', verbose=1, patience=5)\n",
    "    checkpoint = ModelCheckpoint(model_save_path, monitor='val_f1', verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint,es]\n",
    "    \n",
    "    if (cross_validation):\n",
    "        callbacks_list = [es]\n",
    "        his = model.fit(X_train, y_train, epochs=NB_EPOCHS, batch_size=BATCH_SIZE, verbose=1)\n",
    "    else:\n",
    "        his = model.fit(X_train, y_train,validation_data = val_data , epochs=NB_EPOCHS, batch_size=BATCH_SIZE, verbose=1)\n",
    "        #his = model.fit(X_train, y_train,validation_data = val_data , epochs=NB_EPOCHS, batch_size=BATCH_SIZE, callbacks=callbacks_list, verbose=1)\n",
    "    return model,his"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = 300\n",
    "VERBOSITY = 1\n",
    "VALIDATION_SPLIT = 0.1\n",
    "NB_EPOCHS = 15\n",
    "FOLDS = 10\n",
    "EMBEDDING_SIZE = 300\n",
    "\n",
    "BATCH_SIZE = 32 # 64, 128\n",
    "NB_FILTERS = 200 #200\n",
    "FILTER_LENGTH = 4 # test with 2,3,4,5\n",
    "# HIDDEN_DIMS = NB_FILTERS * 2\n",
    "HIDDEN_DIMS = 32\n",
    "MAX_LEN = 210 #test with other values(only this value work for now)\n",
    "DROPOUT_VALUE_1 = 0.5 #0.8 #0.3\n",
    "DROPOUT_VALUE_2 = 0.5\n",
    "L2_REG= 0.01\n",
    "\n",
    "RNN = LSTM\n",
    "\n",
    "model_save_path = \"../trained_models/RNN1.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"RNN_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "main_input (InputLayer)      (None, 64, 16)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 32)                6272      \n",
      "_________________________________________________________________\n",
      "mlp (Dense)                  (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "drop (Dropout)               (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 7,460\n",
      "Trainable params: 7,460\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lahiru/anaconda3/envs/LASER-tf-1/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(32, activation=\"relu\", name=\"mlp\", kernel_initializer=\"he_normal\", kernel_constraint=<keras.con..., bias_constraint=<keras.con...)`\n",
      "  del sys.path[0]\n",
      "/home/lahiru/anaconda3/envs/LASER-tf-1/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, activation=\"softmax\", name=\"output\", kernel_initializer=\"he_normal\")`\n",
      "/home/lahiru/anaconda3/envs/LASER-tf-1/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `Model` call to the Keras 2 API: `Model(name=\"RNN_model\", inputs=Tensor(\"ma..., outputs=Tensor(\"ou...)`\n"
     ]
    }
   ],
   "source": [
    "model = RNN_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(sinhala_std, y_sinhala, test_size=VALIDATION_SPLIT, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Testing...\n",
      "Train on 13553 samples, validate on 1506 samples\n",
      "Epoch 1/20\n",
      "13553/13553 [==============================] - 13s 960us/step - loss: 1.1484 - accuracy: 0.5412 - precision_2: 0.6055 - recall_2: 0.3103 - f1: 0.4007 - val_loss: 1.0585 - val_accuracy: 0.5704 - val_precision_2: 0.6330 - val_recall_2: 0.4124 - val_f1: 0.5004\n",
      "Epoch 2/20\n",
      "13553/13553 [==============================] - 13s 927us/step - loss: 1.0722 - accuracy: 0.5742 - precision_2: 0.6401 - recall_2: 0.4098 - f1: 0.4968 - val_loss: 1.0336 - val_accuracy: 0.5717 - val_precision_2: 0.6383 - val_recall_2: 0.4489 - val_f1: 0.5346\n",
      "Epoch 3/20\n",
      "13553/13553 [==============================] - 13s 930us/step - loss: 1.0374 - accuracy: 0.5878 - precision_2: 0.6592 - recall_2: 0.4445 - f1: 0.5279 - val_loss: 1.0052 - val_accuracy: 0.5916 - val_precision_2: 0.6597 - val_recall_2: 0.4635 - val_f1: 0.5515\n",
      "Epoch 4/20\n",
      "13553/13553 [==============================] - 13s 931us/step - loss: 1.0144 - accuracy: 0.5996 - precision_2: 0.6707 - recall_2: 0.4727 - f1: 0.5527 - val_loss: 1.0211 - val_accuracy: 0.5797 - val_precision_2: 0.6628 - val_recall_2: 0.4582 - val_f1: 0.5489\n",
      "Epoch 5/20\n",
      "13553/13553 [==============================] - 12s 893us/step - loss: 0.9994 - accuracy: 0.6028 - precision_2: 0.6738 - recall_2: 0.4768 - f1: 0.5564 - val_loss: 0.9994 - val_accuracy: 0.5956 - val_precision_2: 0.6551 - val_recall_2: 0.4894 - val_f1: 0.5673\n",
      "Epoch 6/20\n",
      "13553/13553 [==============================] - 12s 893us/step - loss: 0.9854 - accuracy: 0.6083 - precision_2: 0.6805 - recall_2: 0.4845 - f1: 0.5639 - val_loss: 1.0166 - val_accuracy: 0.5916 - val_precision_2: 0.6382 - val_recall_2: 0.5106 - val_f1: 0.5745\n",
      "Epoch 7/20\n",
      "13553/13553 [==============================] - 13s 956us/step - loss: 0.9671 - accuracy: 0.6165 - precision_2: 0.6903 - recall_2: 0.5016 - f1: 0.5786 - val_loss: 0.9967 - val_accuracy: 0.6082 - val_precision_2: 0.6554 - val_recall_2: 0.4887 - val_f1: 0.5676\n",
      "Epoch 8/20\n",
      "13553/13553 [==============================] - 13s 980us/step - loss: 0.9562 - accuracy: 0.6223 - precision_2: 0.6934 - recall_2: 0.5069 - f1: 0.5837 - val_loss: 1.0130 - val_accuracy: 0.5989 - val_precision_2: 0.6475 - val_recall_2: 0.4940 - val_f1: 0.5683\n",
      "Epoch 9/20\n",
      "13553/13553 [==============================] - 13s 926us/step - loss: 0.9412 - accuracy: 0.6279 - precision_2: 0.7017 - recall_2: 0.5124 - f1: 0.5904 - val_loss: 1.0118 - val_accuracy: 0.6016 - val_precision_2: 0.6482 - val_recall_2: 0.4980 - val_f1: 0.5708\n",
      "Epoch 10/20\n",
      "13553/13553 [==============================] - 13s 954us/step - loss: 0.9319 - accuracy: 0.6320 - precision_2: 0.7033 - recall_2: 0.5191 - f1: 0.5954 - val_loss: 1.0194 - val_accuracy: 0.5996 - val_precision_2: 0.6445 - val_recall_2: 0.5272 - val_f1: 0.5876\n",
      "Epoch 11/20\n",
      "13553/13553 [==============================] - 13s 987us/step - loss: 0.9233 - accuracy: 0.6359 - precision_2: 0.7096 - recall_2: 0.5256 - f1: 0.6026 - val_loss: 1.0248 - val_accuracy: 0.5956 - val_precision_2: 0.6351 - val_recall_2: 0.5040 - val_f1: 0.5701\n",
      "Epoch 12/20\n",
      "13553/13553 [==============================] - 14s 1ms/step - loss: 0.9051 - accuracy: 0.6378 - precision_2: 0.7114 - recall_2: 0.5303 - f1: 0.6061 - val_loss: 1.0316 - val_accuracy: 0.6016 - val_precision_2: 0.6477 - val_recall_2: 0.5153 - val_f1: 0.5812\n",
      "Epoch 13/20\n",
      "13553/13553 [==============================] - 13s 946us/step - loss: 0.8974 - accuracy: 0.6428 - precision_2: 0.7143 - recall_2: 0.5389 - f1: 0.6128 - val_loss: 1.0479 - val_accuracy: 0.5830 - val_precision_2: 0.6562 - val_recall_2: 0.4701 - val_f1: 0.5559\n",
      "Epoch 14/20\n",
      "13553/13553 [==============================] - 12s 916us/step - loss: 0.8850 - accuracy: 0.6461 - precision_2: 0.7204 - recall_2: 0.5420 - f1: 0.6170 - val_loss: 1.0367 - val_accuracy: 0.5956 - val_precision_2: 0.6522 - val_recall_2: 0.5206 - val_f1: 0.5868\n",
      "Epoch 15/20\n",
      "13553/13553 [==============================] - 13s 933us/step - loss: 0.8717 - accuracy: 0.6503 - precision_2: 0.7258 - recall_2: 0.5448 - f1: 0.6210 - val_loss: 1.0437 - val_accuracy: 0.5956 - val_precision_2: 0.6587 - val_recall_2: 0.5153 - val_f1: 0.5857\n",
      "Epoch 16/20\n",
      "13553/13553 [==============================] - 13s 925us/step - loss: 0.8580 - accuracy: 0.6539 - precision_2: 0.7293 - recall_2: 0.5521 - f1: 0.6268 - val_loss: 1.0599 - val_accuracy: 0.5956 - val_precision_2: 0.6547 - val_recall_2: 0.4973 - val_f1: 0.5727\n",
      "Epoch 17/20\n",
      "13553/13553 [==============================] - 13s 929us/step - loss: 0.8479 - accuracy: 0.6621 - precision_2: 0.7372 - recall_2: 0.5536 - f1: 0.6305 - val_loss: 1.0992 - val_accuracy: 0.5956 - val_precision_2: 0.6415 - val_recall_2: 0.4801 - val_f1: 0.5502\n",
      "Epoch 18/20\n",
      "13553/13553 [==============================] - 12s 909us/step - loss: 0.8354 - accuracy: 0.6642 - precision_2: 0.7375 - recall_2: 0.5604 - f1: 0.6351 - val_loss: 1.0975 - val_accuracy: 0.6009 - val_precision_2: 0.6373 - val_recall_2: 0.5193 - val_f1: 0.5802\n",
      "Epoch 19/20\n",
      "13553/13553 [==============================] - 12s 912us/step - loss: 0.8231 - accuracy: 0.6687 - precision_2: 0.7416 - recall_2: 0.5733 - f1: 0.6451 - val_loss: 1.0961 - val_accuracy: 0.5910 - val_precision_2: 0.6331 - val_recall_2: 0.5086 - val_f1: 0.5713\n",
      "Epoch 20/20\n",
      "13553/13553 [==============================] - 13s 964us/step - loss: 0.8109 - accuracy: 0.6694 - precision_2: 0.7434 - recall_2: 0.5735 - f1: 0.6460 - val_loss: 1.1432 - val_accuracy: 0.5950 - val_precision_2: 0.6406 - val_recall_2: 0.5007 - val_f1: 0.5632\n"
     ]
    }
   ],
   "source": [
    "train_model,train_his = Train_Model(model,X_train, y_train,val_data = (X_test, y_test), cross_validation = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_accuracy', 'val_precision_2', 'val_recall_2', 'val_f1', 'loss', 'accuracy', 'precision_2', 'recall_2', 'f1'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_his.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA5RklEQVR4nO3dd3zV9fX48dchJATIHqyEjWyQJUNFsVQFB7iqaHFULdrW1v7ar1Vba1vaWju+fq3WVq3SWvdEUbACAu4BKAQIe5kbAoRAJtn3/P543+A13kDGvbkZ5/l43Af3ftY9+XDv59zPe4qqYowxxtTWIdwBGGOMaZksQRhjjAnIEoQxxpiALEEYY4wJyBKEMcaYgCxBGGOMCcgShDEhIiL/FpHf1XPbPSLyzTrWdRaR10WkQEReDG6UxtTNEoQxLd9lQHcgWVW/JSI9RWSRiOwTERWRfmGOz7RRliCMafn6AttUtcr32gv8F7g0fCGZ9sAShGnXfEU7t4lIhoiUiMjjItJdRN4UkSIRWS4iiX7bzxKRTSKSLyKrRGSY37qxIvKZb7/ngeha73WBiKzz7fuhiIyuR3y/Ae4GrhCRYhG5QVUPqOrfgdXBOxPGfJ0lCGPcL/GzgcHAhcCbwM+BVNx35EcAIjIYeBb4sW/dEuB1EYkSkSjgVeBJIAl4Eb9f+CIyFlgA3AQkA48Ai0Sk0/ECU9VfAfcAz6tqjKo+HpS/2Jh6sARhDDzo+1WeDbwHfKKqn6tqGbAQGOvb7gpgsaouU9VK4C9AZ+BUYDIQCdyvqpWq+hJf/YU/D3hEVT9R1WpVfQIo9+1nTIvUMdwBGNMCHPB7XhrgdYzveS9gb80KVfWKSBaQBlQD2frV0S/3+j3vC1wrIj/0WxblO6YxLZIlCGPqbx8wquaFiAjQG8gGFEgTEfFLEn2Anb7nWcDvVfX3zRivMU1iRUzG1N8LwPkiMl1EIoGf4oqJPgQ+AqqAH4lIpIhcAkz02/efwM0iMkmcriJyvojENiYQEYkGauovOvleGxNUliCMqSdV3QrMBR4EDuEqtC9U1QpVrQAuAa4DDuPqK17x23cN8F3gb8ARYIdv28YqBYp9z7f4XhsTVGITBhljjAnE7iCMMcYEZAnCGGNMQJYgjDHGBGQJwhhjTEBtph9ESkqK9uvXL9xhGGNMq7J27dpDqpoaaF2bSRD9+vVjzZo14Q7DGGNaFRHZW9c6K2IyxhgTkCUIY4wxAYU0QYjIDBHZKiI7ROSOOra5XEQyfWPsP+O3vNo3dv46EVkUyjiNMcZ8XcjqIEQkAngIN86+B1gtIotUNdNvm5OAO4HTVPWIiHTzO0Spqo5pSgyVlZV4PB7KysqacphWITo6mvT0dCIjI8MdijGmjQhlJfVEYIeq7gIQkeeA2UCm3zbfBR5S1SMAqnowmAF4PB5iY2Pp168fbuDNtklVycvLw+Px0L9//3CHY4xpI0JZxJSGG+K4hse3zN9gYLCIfCAiH4vIDL910SKyxrf8okBvICLzfNusyc3N/dr6srIykpOT23RyABARkpOT28WdkjGm+YS7mWtH4CRgGpAOvCsio1Q1H+irqtkiMgBYISIbVHWn/86q+ijwKMCECRMCjjrY1pNDjfbydxpjmk8oE0Q2bjKVGum+Zf48uOkdK4HdIrINlzBW+6Z/RFV3icgq3LSPOzHGmDZMVSmv8lJWWc3RCveoeV5aWU1pRZXfc7c8JaYTV03qE/RYQpkgVgMniUh/XGKYA1xVa5tXgSuBf4lICq7IaZeIJAJHVbXct/w04E8hjDVk8vPzeeaZZ/j+97/foP3OO+88nnnmGRISEkITmDEm7DbnFPK3FTvYkF3gLvoVVZRWVuNt4CwM4/oktK4EoapVInIL8BYQASxQ1U0iMh9Yo6qLfOvOEZFM3Jy+t6lqnoicCjwiIl5cPcm9/q2fWpP8/Hz+/ve/fy1BVFVV0bFj3ad/yZIloQ7NGBMmW/cX8de3t7Fkw35iO3Vk2tBuxHTqSJeoCDpHRtA5KqLW845fW94lyr3uHBlBx4jQVCeHtA5CVZcAS2otu9vvuQI/8T38t/kQv7l/W7M77riDnTt3MmbMGCIjI4mOjiYxMZEtW7awbds2LrroIrKysigrK+PWW29l3rx5wJdDhxQXFzNz5kxOP/10PvzwQ9LS0njttdfo3LlzmP8yY0xDbT9QxP1vb2fJhhy6RnXkh98YxA2n9yehS1S4Qwso3JXUzeY3r28ic19hUI85vFccv7pwxHG3uffee9m4cSPr1q1j1apVnH/++WzcuPFYc9QFCxaQlJREaWkpp5xyCpdeeinJyclfOcb27dt59tln+ec//8nll1/Oyy+/zNy5c4P6txhjQmfHwWIeeHs7r2fso3NkBN87cyDfnTqAxK4tMzHUaDcJoqWYOHHiV/oqPPDAAyxcuBCArKwstm/f/rUE0b9/f8aMGQPA+PHj2bNnT3OFa4xpgl25xTy4YgevrcsmOjKCm84YyLwzBpDUwhNDjXaTIE70S7+5dO3a9djzVatWsXz5cj766CO6dOnCtGnTAvZl6NSp07HnERERlJba/PTGtGR7DpXwwIrtvPp5Np06RvDdqQOYd8YAkmM6nXjnFqTdJIhwiY2NpaioKOC6goICEhMT6dKlC1u2bOHjjz9u5uiMMcH0Rd5RHlixnYWfZ9Oxg3D9af256cyBpMa2rsRQwxJEiCUnJ3PaaacxcuRIOnfuTPfu3Y+tmzFjBg8//DDDhg1jyJAhTJ48OYyRGmMaK+vwUf62YgcvfeYhooNw7ZR+3DxtAN1io8MdWpOIa0jU+k2YMEFrTxi0efNmhg0bFqaIml97+3uNCZeqai9b9hexes9hPt19mGWZB+jQQbhqYh++N20g3eNaT2IQkbWqOiHQOruDMMaYEygpr2JdVj6r9xxm7d4jfLb3CCUV1QCkJXRm7uS+3HzmQHrEt57EUB+WIIwxppaDRWWs2XPEPfYeZtO+Qqq9iggM7RHHpePTmdAviQl9E+mV0Hb7JFmCMMa0a6rKztwS1uw5zGpfQtibdxSA6MgOjOmdwPenDWRCvyTG9kkgLrr9zLliCcIY026UV1Wz/UAxmTmFbM4pJHNfIZk5hRSVVQGQ1DWKCX0TmTupLxP6JTKiVzxRHdvvzMyWIIwxbVL+0Qoy/ZJA5r5Cdhwspso3El7nyAiG9oxl1sm9GJ0ezyn9kuif0tWGzvdjCcIY06qpKp4jpWzySwSbcwrJzv+yQ2m32E4M7xXHN4Z2Y3ivOIb3jKNvclciOlgyOB5LECHW2OG+Ae6//37mzZtHly5dQhCZMa1XwdFK3tuRy8otubyz7SCHiisA6CAwIDWG8X0TuXpKX4b3jGNYz7hW21Et3CxBhFhdw33Xx/3338/cuXMtQZh2T1XZsr+IlVsPsmpLLmu/OEK1V4nvHMmZg1OZNCCJEb3iGdI9ls5REeEOt82wBBFi/sN9n3322XTr1o0XXniB8vJyLr74Yn7zm99QUlLC5Zdfjsfjobq6ml/+8pccOHCAffv2cdZZZ5GSksLKlSvD/acY06yKy6t4f/shVm09yKqtuewvdOOUjegVx/fOHMhZQ1M5OT0hZHMhmPaUIN68A/ZvCO4xe4yCmfcedxP/4b6XLl3KSy+9xKeffoqqMmvWLN59911yc3Pp1asXixcvBtwYTfHx8dx3332sXLmSlJSU4MZtTAvkmpsWs3JLLiu3HmT1nsNUVisxnToy9aQUzhrSjTOHpLaqXsqtXftJEC3A0qVLWbp0KWPHjgWguLiY7du3M3XqVH76059y++23c8EFFzB16tQwR2pM6Kkq+wvLWJ9VwAc7DrFy60E8R1zF8uDuMVx/Wn+mDenG+L6J7bqpaTi1nwRxgl/6zUFVufPOO7npppu+tu6zzz5jyZIl3HXXXUyfPp277747wBGMab0OFpWxwVNAhqeADdnu30PF5YBrcnraoGRuPnMg04akkp5o9W4tQftJEGHiP9z3ueeeyy9/+Uu+/e1vExMTQ3Z2NpGRkVRVVZGUlMTcuXNJSEjgscce+8q+VsRkWpvDJRVsyC5ggyef9Z4CNngKjtUhiMCg1BjOGJzC6LR4RqUnMKJXHNGRVrnc0liCCDH/4b5nzpzJVVddxZQpUwCIiYnhqaeeYseOHdx222106NCByMhI/vGPfwAwb948ZsyYQa9evayS2rRYBaWVbMyuuTPIJ8NTcKyoCGBASlcmDUhiVFo8o33JoGsnu/S0BjbcdxvS3v5e0/zKKqvZnFPI+ix3Z7A+K59dh0qOre+T1IVR6fG+O4N4RqbFt6uxi1ojG+7bGNNgXq9rVVSTCNZ78tmcU0hltftRmRrbiTG9E7h0fLrv7iCehC6tY65lUz+WIIwxfi2K8lmX5RLChuwCisvdIHYxnToyOj2eG6cO4OT0eE7unUCPuGgbt6iNa/MJQlXbxYe4rRQVmuZTWlHNyq0HWbwhh9W7D3OwyLUoiowQhveM4+KxaZzcO4ExveMZkBJDBxu3qN1p0wkiOjqavLw8kpOT23SSUFXy8vKIjrYOROb4yiqrWbU1l8Ubcnh78wGOVlSTEhPF1JNSGdM7gZN7JzCsZyydOlqLItPGE0R6ejoej4fc3NxwhxJy0dHRpKenhzsM0wKVVVbz3vZDvJGxj+WZByipqCa5axQXj03j/NE9mdQ/2UY1NQG16QQRGRlJ//79wx2GMc2uosrLe9tzWZyRw7LMAxSVV5HYJZJZY3px/qheTB6QZGMYmRNq0wnCmPakosrLBzsPsTgjh7c27aeorIr4zpHMHNWDC0b3YsrAZCItKZgGsARhTCvl9SrZ+aVk5hSyYvNB/rtpPwWllcRGd+TcET04f3RPThuYYuMYmUazBGFMK1BwtJIt+wvZeqCIzTlFbN1fyNb9RZRUVAOuGeo5w7tz/uienH5SilUym6CwBGFMC1JR5WVnbjFb9xex2ZcEtu4vIqeg7Ng2CV0iGdI9lsvGpzO0ZxxDesQyvKeNZWSCL6QJQkRmAH8FIoDHVPVrQ6qKyOXArwEF1qvqVb7l1wJ3+Tb7nao+EcpYjQmHg4VlLN6Qw+df5LN1fxE7c4up8ro+LZERwqBusUwekMyQHrEM7RHL0B5xdI/r1KabbZuWI2QJQkQigIeAswEPsFpEFqlqpt82JwF3Aqep6hER6eZbngT8CpiASxxrffseCVW8xjSXkvIqlmbu55XPsvlgxyG8CmkJnRnaI5bpw7oxtGccQ3vE0j+lq1Uqm7AK5R3ERGCHqu4CEJHngNlApt823wUeqrnwq+pB3/JzgWWqeti37zJgBvBsCOM1JmSqqr28v+MQr36ezVubDlBaWU1aQme+P20QF43txaBuseEO0ZivCWWCSAOy/F57gEm1thkMICIf4Iqhfq2q/61j37TabyAi84B5AH369Ala4MYEg6qyMbuQhZ9ns2j9Pg4VlxPfOZKLx6Vx8dg0xvdJtOErTIsW7krqjsBJwDQgHXhXREbVd2dVfRR4FNxw36EI0JiGyjp8lNfWZbPw82x25pYQFdGBbwztxkVj0zhraKq1MDKtRigTRDbQ2+91um+ZPw/wiapWArtFZBsuYWTjkob/vqtCFqkxTVRwtJLFG3J49fNsPt1zGICJ/ZO4ceoAzhvZk/guNieCaX1CmSBWAyeJSH/cBX8OcFWtbV4FrgT+JSIpuCKnXcBO4B4RSfRtdw6uMtuYFsHrVTbvL+TjXYf5cMch3tt+iIpqL4O6xXDbuUOYPaaXzatsWr2QJQhVrRKRW4C3cPULC1R1k4jMB9ao6iLfunNEJBOoBm5T1TwAEfktLskAzK+psDYmHLxeZeuBIj7elcdHO/P4ZPdhCkorAeiX3IW5k/tyybg0RvSKsyaops1o01OOGtNYqsq2A8V+CSGPI0ddQuid1JkpA5KZ7Hv0Sugc5miNaTybctSYE1BVdhz0JYRdeXyy6zB5JRWA66MwfVh3X0JIsqIj025YgjDtVlllNe9sy2XJhhw+2HGIQ8UuIfSKj+bMIalMHpDMlAHJ9E6yhGDaJ0sQpl0pr6rm/e2HeMM3T0Kxb56EMwenMmWgKzLqk9TF6hGMwRKEaQcqfb2Ya8+TcF6w5knYtQoS+kKSTU5l2hZLEKZNqqr28tGuPN5Yn8NbmfvJP+rmSThneA8uGN2T0wYFYZ4ErxdW/Bbevw+i42HOs9DvtOD8Aa2FKiz/Nez9ADrFQadYiI7zPY/zPY+t9Tz+y+06RoPdrbVYliBMm1HtVT7ZlccbG3L478b9HC6poGtUBGcP784Fo3sxdXAQ50moKIGFN8Hm1+HkqyB7DTx5EVz8MIy8NDjv0RpsWggf3A89x0BZPuR/AeVFUF4IlUdPvH+HSJcsBp4F5/4BYruHOGDTEJYgTKtWVlnNZ3uP8ObG/by5cT+HisvpEhXB9GHduWB0T84cnBr8eRIKc+DZOZCzHs69ByZ/H0qPwHNXwUvXQ0E2nPrDtv/L+OhhePNnLjnc+DZE1LqcVFd+mSzKCr98Xl4EZQVfPi/JhYwXYcfbMONeOHlO2z93rYQlCNOqVFV72ZBdwIc78/hw5yHW7DlCeZWX6MgOTB/qZlQ7a0g3OkeFaLyjfevg2Svdxe3KZ2HITLe8SxJc/aq7q1j2SyjIche7Dm143KWlv3RJYu4rX08OABGR7rx0STrxsU69FRbdAq/eDBtfggvuh4TeJ9zNhJYlCNOieb3Klv1FfLjz0LEezMXlVQAM6xnH3Ml9mTIgmSkDk+naKcQf581vwCvfhc5JcP1b0GPkV9dHRsNl/4Jl6fDR36BwH1zyT4gKcTPZw7tcTJ0TQvs+/nauhHVPwek/gZ6jm3681MHwnTdh9WOw/Dfw98lw9m9g/PXQwebECBfrSW1aFFVl16ESPtyZx0e+pFDTg3lASlemDEzmtEEpTOqfRHJMp+YKCj74q6uMTRvnKqNPVFb+8cPw3zsgfQJc+Rx0TQl+XIX7YMXvYN0z0H0E3LAs9MkIoOKou4B36Ajf+wAig9yT/MheeP1HrnVY39Ng1oOQPDC47xFMu99zxWTDLnR3Ta3M8XpSW4IwYXegsIx3tuXyka/Y6EBhOeB6ME8ZmMypA90dQs/4MAxpUVUBb/w/92t5xMVw0T/qf0HMXOTuOOJ6wbdfCt5FrrwYPnwAPnwQvFUurowXYPTlcPEjoS+/f+sX7g7pusXQ7/TQvIcqfP6Ue6/qcjjr5zD5B4GLssLpyB74+6lQWQKxvWDSTTD+uua9m2siSxCmRVJVnvrkC377RiYVVV5SYqKYMjCFU31JIewd1o4ehuevhr3vw5m3w5l3NLy444tPXIW2CFz1grujaCxvNax7Glb8Hor3u8TwzV9DYj9450+w8vcw888waV7j3+NEsj+Dx6bDuGvgwr+G7n1qFObAkv+BLW9Ar7Ew+yF3t9QSeL3wn1muXur8v7j/m93vQmRXGHc1TLq5VfSNsQRhWpyC0krueDmDNzfu58zBqfz8vGEM7h7TcnowH9oOT3/LFePM/pv7dd7oY+2Apy+FogNw2eMw9PyGH2PnClcpfGAjpJ/iWk/1nvjleq/XtaLascz9su8zufHx1qW6Eh49yxWn/OCT5vuVrOqa0y65zbV+mvpT9+gY1TzvX5fVj8Pin7gK9QnfcctyMuCjh1xFu3ph6AUw5RboU3syzZbDEoRpUT774gg/fOZzDhSW8bMZQ7jx9AEta+rNXavghWtcG/05zwTny12cC89cDjnrYOafYOJ367ffwc0uMexY5nprf/PX7s4hUCItzYdHp0FlKdz0bvD7FLz3v/D2fLjiaRh2QXCPXR8lefDWnZDxPHQb7hJ32vjmjwNcf4+/T3Hvf81rX///KNwHnz4Kaxa4pJZ+Ckz5AQy9sMUVk1mCMKFxeJcr+978BsSnw6jLXLPPqK4BN/d6lUff28Vf3tpKj/hoHrxyLGP7JAbcNmzW/MsVaSSfBFc9D4l9g3fsihJ46QbY9iacditM/3XdRVbFB2HlPfDZExAVC2f8jyvf7niCivn9G+Gxb7rimGsXBa/S9NAO+MepMPhcuOLJ4Byzsba9Ba//2BWzTf4+nPWL5qmcr6EKT14MWZ/C9z86/mekvBjWP+vuKo7shoQ+MOl7rgiqU2zzxXwcliBM8JTkwaZXXGLwfAqIK844sheK9kFkF5ckRl4Gg6Yfu6AdKi7nJy+s591tuZw/qif3XDKK+M4tqMWHt9r9Uv/4IRh0Nly2wA0FEWzVVa5z2ZrHXY/ri/7x1Yt+Zam7mLx/P1SVwoQbXP1H1+T6v0fGi/DKje7iOeMPTY/Z64UnLnDFWz/4FGJ7NP2YTVVWAMt+BWv/BUkDXOW8f5FbKK19wrWyOu8v9b8T9FbD1jdd5f4XH7mhR8Zf6+op4tNDG+8JWIIwTVNZCtv+65LC9qWu5Uy34TD6CnfXEJ/uLiJffAgbXoLM16D0sBufaNgsNiadzQ3vRJNf5uXuC4dz1cQ+LaeuAVxv3pdvdH/jpJvhnN+HthhAFd7/P3j7N9D3dJjzlBufaMOLrgin0ANDzoez50PKoMa9x5u3wycPw6WPu/+jpljzL3jjx6656bhrmnasYNv9Lrx2i2tQ8J0lwemTcTwFHle01PNkuGZR4/poeNa6RJH5mns94mKXzNPGhaUHuSUI03BerxuALeN590EuL4TYnu5iM/oK6DGq7n2rK2HnSrwbXqRq0xtEeY+SJ4nIiItJmnSlK49t7i+CtxqK9kP+Xld+nP+Fu+vJ3wu5W9wFZuYf6/+LMBgyXoRXv+eav0Z2hn2fuwvPufc0vflodSU8caEbDuTG5Y1v+VOYAw9NdHFd+3rLHAKjcB88drb74XLj8tD1wFaFpy+DvR/C9z5segul/C/gk0fcHUlFkTvHE653d9+dYoITcz1YgjD1d3AzrH/O3QkUeiAqBobNgpOvgH5T6z10xL78Un707Ods3Lufu07KYk7nT+i4c7lr057QxxWvjLzMXbiCcdHxeqH4wJcX//w9X00EBR7wVn51n5gervw4oY/7Zdz/jKbH0VC734Xn5roLwvS7YdTlwes5XLQfHjnD1Ql9d2XDWx2pwvNzYcdyd0FsyZ3VDm6Gx8+FuJ5w/X+hcwjqtj5/Gl77Psz4I0y+OXjHLSuEDS/A6gVwcJMrfhp9hWsZ1QxNei1BmOMr2u+KNzKeh/0bQCJc/cHoK2DIeQ2uAFy6aT+3vZRBVbWXey4ZxewxaW5FWQFsWeySz65VoNWQOtQlivh0V+ZeVe6KtKrKa70uc4/KMr/nftsVHXDJx1/XVHfxT/AlgZpkkNAX4nu7oTFagtIjru7mRBXQjfHFx/Dv8129ypxnGpZ8Ml9zrbm++Rs4/cfBjy3Ydr8HT13i7lCvXhjc81m4Dx6a7C7Y1y0OzfAfqq7ie80C16y3uhx6T3Z3FcNnh+zzagnC1G3H264zWGWJa7I3+goYcQnEpDb4UOVV1fxhyRb+/eEeRqbF8bcrx9EvJXCLJopzIfNV2Piyq7QLJKKTmy8gMtr9W/u5/+uYbr5EUJMEetfZmqrd+eQRVzH+jbvgjNvqt0/pEXhoEsR0d3cfLaxpZp02vAQv3+A+w5c+HpwLuarr7LhrVfPdSR097DrerVnw5VhbY78N478T9Pe3BGEC27QQXv6u+xV/2QI3YFoj7T5Uwi3PfMamfYVcf1p/bp85pP5zLxQfhIpi6NjZ/eqL7OySgw3SFhyq8Mo8d5c49yUY9M0T7/PaLW6Mp++ugF5jQh5iUH3wgBtR99Qfwjm/a/rx1j8PC+e5uqEpP2j68RrC64U977pEsWWxq2cZMM21bhsyMyjNmI+XIFrJzwITdGv/7cYYSp/o2vs3sldsRZWXhZ97mP96JpEdO/DYNRP45vAGdtCK6QZ0a9T7m3oQccNiHMx0rbXmvXP8tvu73oHPn3R9NVpbcgCXGAo8bqyquPSm1RcU7Xd3X+kTXQu35tahg0sIA6a5WD570n13X7ja1aGNu8Y1lw1RU1m7g2iP3r8flv/KlUtf/p9GdTLK3FfIi2uzeG3dPg6XVHBKv0T+OmcsvRLCMKCeqZ/Du+CRaS453LA08KCDFUddhzhwncCCPVJrc/FWu/qTLYvh8idcGX5DqcJz3/ZV0n8AKScFP87G8Fa75uZrFsD2Ze4HwIhL4NLHGtXgw+4gjFMzf/AH9/s6aT3coPFs8o9W8Nq6fby4NouN2YVERghnD+/Ot8b35ozBqUS0pOEyzNclDYBLHoVnr4DFP3UD39W+oLxzr+vxe+3rrTc5gGttd+lj8MQsV4wa073h41NtfBm2Lvb1R2khyQHc3zZkpnsc2et626s3JE2Q7Q6ivfBWuyKlz55wrSLO+0u9mqxWe5X3tufy4loPyzYdoKLay/CecVw+IZ3ZY9JI7BrmAdNMw628B975I5x/H5xyw5fL962Df37DVYbOejBs4QVVSR4sOAeO5sH1S+tfz1Z80FXSJw1wd1tteGZAu4No76rKXSVl5qsw9X9ca5YT/NrYfaiEl9Zm8fLabPYXlpHQJZKrJvXhWxPSGdErvnniNqFx5h1u2O43b4ceo6H3KW4IkEU/dBMbnT0/3BEGT9dkNxfH42e7EXVvWF6/QQwX/9Q1nJj9UJtODidiCaKtqyhxnZ12rnAtOk79YZ2blpRXsXhDDi+uyWL1niN0EDhzcCp3Xzic6cO61b9VkmnZOnRwRU2PTnPl9De965pU7s9wdVKh6GQWTkn93Vwc/z4fnvkWXLfk+D2VNy2EzYtg+q+g29Dmi7MFsiKmtqz0CDx9OWSvgQsfcCNI1lJQWskGTwGvrctm8YYcjlZUMyClK5dNSOeSsen0iG8hnclM8OVkuF/W3UfAgU2u+eucp8MdVehsW+r6Mww8y00DG6iJaMkhN7RIQh93t9Fa+n80gRUxtUdF++HJSyBvO3zrCXTYhXgOHyUzp5DNOYVk7iskM6cQz5FSALpGRXDh6F5cfko64/oktqzB9Exo9Bztmr8uvMkNFnjeX8IdUWgNPgcuuA9ev9XVx8168OtFrUtuc0NfzP57u0gOJ2JnoA0qz92J/OciOhzN5ZkBf2Hxe6lkvrCUorIqwH0nBqR0ZWyfRK6a1IdhPeOY1D+JLlH2cWh3Tp4DlUchsb8bx6itG38dFGTDu39yfQem3fHlusxFbij7s+6C7sPDFmJLEtIrgojMAP4KRACPqeq9tdZfB/wZyPYt+puqPuZbVw1s8C3/QlVnhTLW1mxjdgEf78ojM6eQkqwNzC+8iyiq+E7FnWzd0p1hPb3MOrkXw3vFMbxnHEN6xFoyMF+acH24I2heZ/3cdaRb9QeIS3NFr0cPu+lDe4xuHeNONZOQXSVEJAJ4CDgb8ACrRWSRqmbW2vR5Vb0lwCFKVXVMqOJrMVRh9zuuFUliPzeGUAMGGVu19SDf+fdqVGF6zF7+6r0HjYpm7Zn/4b4h4+mb3NX6JxjjTwRmPeBmpHv9VjeMfcbzrs7u6oXBm4WvDQjlz8iJwA5V3QUgIs8Bs4HaCaL98p9d7Bhxv2qS+rser4n93O1/Yj/36JJ8rNx0z6ESfvTs5wzpHsuz00tJXPRbiO8O17zGtGBOlWlMWxMR6Vps/WsmPHeVGzl12p3Hn+ekHQplgkgDsvxee4BAs79fKiJnANuA/6eqNftEi8gaoAq4V1VfDWGsza+sEF68Dna+7ca8GTwTjuz56mP7cvcrx19UDCT2oyq+D2v2RHKlpHDz6L4kLvwtpA6Bua8Ef7J6Y9qiTrGuj8RjZ7uxyE7/SbgjanHCXRD9OvCsqpaLyE3AE8A3fOv6qmq2iAwAVojIBlXd6b+ziMwD5gH06dOnOeNumvwv4Jkr4NA21/x0/LVued8pX9+24qib9cwvceiR3RzcvYkLKvYRLZXwLtB7kmvr3chB94xpl2J7wA8+BqRBw860F6FMENmA/9x/6XxZGQ2Aqub5vXwM+JPfumzfv7tEZBUwFthZa/9HgUfB9YMIYuyhk70WnpnjejfPfdmN0ng8UV2g2zD38HloxXb+krGNu84bwo1jY9xkJt1H2gfcmMaweUPqFMoB91cDJ4lIfxGJAuYAi/w3EBH/dnWzgM2+5Yki0sn3PAU4jbZQd5H5GvzrfDcI2o3LTpwcAlix5QD/u2wbF43pxQ1TB7pfQGnjLDkYY4IuZHcQqlolIrcAb+GauS5Q1U0iMh9Yo6qLgB+JyCxcPcNh4Drf7sOAR0TEi0ti9wZo/dR6qMIHf3VDbKdPdFM/NmLGtp25xdz67DqG94zjD5eMts5sxpiQsqE2Qq260rWv/uw/bsz2i/7eqGGUi8oqueihDzhytJJFt5xGemLD53AwxpjabKiNcCnNd4Oh7X7HjaJ61i8aNY2m16v85IX17Mk7ypM3TLTkYIxpFpYgQuXIHjdQ3uFdcNE/YMxVjT7UAyu2syzzAL+6cDinDkwJXozGGHMcliBCIetTePZKN8H41Quh/9RGH2pZ5gHuX76dS8alcd2p/YIXozHGnEAoWzG1Txtfhn9f4Drh3Li8Sclhx8Ei/t/z6xidHs89F4+ySmljTLOyBBEsqvDun+Gl612z0xvfbtI8toVllcz7z1qiIzvw8NzxREfaZD3GmOZlRUzBUFXhBv1a/wyMuhxm/61BA+7V5vUqP35uHV8cPsrTN06iV0IrnjzeGNNqWYJoqupKeOoS2POeG+zrzNtPON/zifzf8m2s2HKQ+bNHMGlAcpACNcaYhrEE0VSf/tMlB/8xlZrgvxtzeHDFDi6fkM7Vk21EVmNM+FgdRFOUHIJV98LA6TDumiYfbuv+In7ywnrG9E5g/uyRViltjAkrSxBN8fZ8qCyBGfc2uVip4Ggl855cQ9dOHa1S2hjTIliCaKx969zwGRNvgtTBTTpUtVf50XOfsy+/lH98exw94qODE6MxxjSB1UE0hiq8ebub3e3MnzX5cH9ZupV3tuXy+4tHMqFfUhACNMaYprME0RgbX4asj+HCvzZ5gp6Pdubxj1U7uXJib749ySqljTEthxUxNVRFCSy7G3qMhrFXN+lQZZXV/HzhBvokdeHuC0YEKUBjjAmORiUIEYkJdiCtxvv3Q2E2zPwTdGhaRfKDK7az+1AJ91w8is5RViltjGlZGnsH0Xon72mKI3vhwwdg5GWB549ugM05hTzyzi4uHZfO6SfZCK3GmJanzjoIEflJXauA9nkHsfQukA5w9vwmHabaq9zxcgbxnSO56/xhJ97BGGPC4Hh3EPcAiUBsrUfMCfZrm3a/C5sXwek/gfi0Jh3q3x/uYb2ngF/NGkFiV5tL2hjTMh2vFdNnwKuqurb2ChG5MXQhtUDVVa5Za0IfOPWWJh0q6/BR/vLWVs4aksqFo3sGKUBjjAm+490JZAN7ReTWAOsCzl/aZq39FxzMhHN+16j5pGuoKr94dSMi8Dub38EY08IdL0EMB6KA60UkUUSSah5AZfOE1wIcPQwrfw/9psKwWU061Gvr9vHutlxuO3cIaTaEtzGmhTteEdMjwNvAAGAtrnK6hvqWt30r74GyApj5xyaNt3S4pIL5b2QypncC10zpF7z4jDEmROq8g1DVB1R1GLBAVQeoan+/R/tIDgc2wZrHYcIN0L1pHdl+90YmhaWV3HvpKCI6WNGSMablO2FrJFX9XnME0uLUjLcUHQ9n/bxJh3p3Wy6vfJ7N96YNZGiPuCAFaIwxodX+mqvW1+ZFbiKgs34BXRo/gN7Riip+vnADA1K78oOzBgUxQGOMCS0brC+QylLXKa7bCBj/nSYd6v+WbcNzpJTn5022OR6MMa2KJYhAPvwb5H8B174OEY0/RRmefB5/fzdXTuxjc0sbY1odK2KqrSAb3r/PNWntf0ajD1NZ7eX2lzeQEtOJO2YODWKAxhjTPOwOorZld4N6Xae4Jnjsvd1szink4bnjie8cGaTgjDGm+dgdhL+9H8HGl+DUH0Fi4yfv2XOohPuXb+PcEd2ZMbJHEAM0xpjmYwmihrca3vwZxKXB6T9u9GFUlTtf2UBURAfmzx4ZvPiMMaaZWYKo8flTsD/DDeUd1bXRh3lxjYePduVxx3lD6R4XHcQAjTGmeYU0QYjIDBHZKiI7ROSOAOuvE5FcEVnne9zot+5aEdnue1wbyjgpzYe350OfKTDy0kYf5mBRGb9fspmJ/ZK48pQ+wYvPGGPCIGSV1CISATwEnA14gNUiskhVa89G97yq3lJr3yTgV7hRYxVY69v3SEiCfedPcDQPZr7SpPGWfvN6JqUV1dxzySg62HAaxphWLpR3EBOBHaq6S1UrgOeA2fXc91xgmaoe9iWFZcCMkESZtxM+fQTGXQM9T270YZZnHmBxRg4//MYgBnVrnxPuGWPallAmiDQgy++1x7estktFJENEXhKR3g3ZV0TmicgaEVmTm5vbuCgT+8OFf4Xpdzduf6CorJJfvraRId1juenMgY0+jjHGtCThrqR+HeinqqNxdwlPNGRnVX1UVSeo6oTU1NTGRdChA4ydC11TGrc/8Oe3trK/sIw/XDqKqI7hPqXGGBMcobyaZQO9/V6n+5Ydo6p5qlrue/kYML6++7YUecXlPPnxXuZO6su4PonhDscYY4ImlAliNXCSiPQXkShgDrDIfwMR8Z+UeRaw2ff8LeAc30x2icA5vmUtznpPPqpwgc0vbYxpY0LWiklVq0TkFtyFPQI38dAmEZkPrFHVRcCPRGQWUAUcBq7z7XtYRH6LSzIA81X1cKhibYr1WQWIwIi0+HCHYowxQRXSsZhUdQmwpNayu/2e3wncWce+C4AFoYwvGDI8+QxKjSGmkw1rZYxpW6xGtQlUlQxPAaPTE8IdijHGBJ0liCbIzi8lr6SCk3tb8ZIxpu2xBNEEGZ4CALuDMMa0SZYgmmC9J5/ICGFYz9hwh2KMMUFnCaIJMrIKGNojjk4dba5pY0zbYwmikbxeZWN2AaPTrf7BGNM2WYJopF2HSigqr+Jkq38wxrRRliAaaUN2PgCjrQWTMaaNsgTRSOuzCugcGcGgVBva2xjTNlmCaKQMTz4j0+LoGGGn0BjTNtnVrREqq71s2ldo/R+MMW2aJYhG2HagiPIqr7VgMsa0aZYgGqGmB7W1YDLGtGWWIBohw5NPfOdI+iZ3CXcoxhgTMpYgGmF9lusgJyLhDsUYY0LGEkQDlVVWs/VAkdU/GGPaPEsQDbRpXyHVXrUWTMaYNs8SRANlePIBq6A2xrR9liAaKMNTQLfYTvSIjw53KMYYE1KWIBpovSffipeMMe2CJYgGKCyrZFduCSdbBbUxph2wBNEAG2umGO2dEN5AjDGmGViCaID1NQkize4gjDFtnyWIBsjw5NMnqQuJXaPCHYoxxoScJYgGyPDYFKPGmPbDEkQ9HSouJzu/1Po/GGPaDUsQ9VTTQc7uIIwx7YUliHpan1WACIywCmpjTDthCaKeMjz5DEqNIaZTx3CHYowxzcISRD2oqq+COiHcoRhjTLOxBFEP2fml5JVUcHJvK14yxrQfIU0QIjJDRLaKyA4RueM4210qIioiE3yv+4lIqYis8z0eDmWcJ1IzxajdQRhj2pOQFaiLSATwEHA24AFWi8giVc2stV0scCvwSa1D7FTVMaGKryHWe/KJjBCG9YwNdyjGGNNsQnkHMRHYoaq7VLUCeA6YHWC73wJ/BMpCGEuTZGQVMLRHHJ06RoQ7FGOMaTahTBBpQJbfa49v2TEiMg7oraqLA+zfX0Q+F5F3RGRqoDcQkXkiskZE1uTm5gYtcH9er7Ix23pQG2Pan7BVUotIB+A+4KcBVucAfVR1LPAT4BkRiau9kao+qqoTVHVCampqSOLcnVdCUXmV9aA2xrQ7oUwQ2UBvv9fpvmU1YoGRwCoR2QNMBhaJyARVLVfVPABVXQvsBAaHMNY6HetBbS2YjDHtTCgTxGrgJBHpLyJRwBxgUc1KVS1Q1RRV7aeq/YCPgVmqukZEUn2V3IjIAOAkYFcIY63T+qwCOkdGMCg1Jhxvb4wxYROyVkyqWiUitwBvARHAAlXdJCLzgTWquug4u58BzBeRSsAL3Kyqh0MV6/FkePIZmRZHxwjrMmKMaV9COm6Eqi4BltRadncd207ze/4y8HIoY6uPymovm/YVMndy33CHYowxzc5+Fh/HtgNFlFd5rQWTMaZdsgRxHDU9qK0FkzGmPbIEcRwZnnziO0fSN7lLuEMxxphmZwniONZnuQ5yIhLuUIwxptlZgqhDWWU1Ww8UWf2DMabdsgRRh037Cqn2qo3gaoxptyxB1KGmB7VVUBtj2itLEHXI8BTQLbYTPeKjwx2KMcaEhSWIOqz35FvxkjGmXbMEEUBhWSW7cks42SqojTHtmCWIADbWTDHaOyG8gRhjTBhZgghgfU2CSLM7CGNM+2UJIoAMTz59krqQ2DUq3KEYY0zYWIIIIMNjU4waY4wliFoOFZeTnV9q/R+MMe2eJYhajk0xancQxph2zhJELeuzChCBEVZBbYxp5yxB1JLhyWdQagwxnUI62Z4xxrR4liD8qKqvgjoh3KEYY0zYWYLwk51fSl5JBSf3tuIlY4yxBOGnZopRu4MwxhhLEF+R4SkgMkIY1jM23KEYY0zYWYLwk+HJZ2iPODp1jAh3KMYYE3aWIHy8XmWD9aA2xphjLEH47M4roai8ynpQG2OMjyUIn2M9qK0FkzHGAJYgjlmfVUDnyAgGpcaEOxRjjGkRLEH4ZHjyGZkWR8cIOyXGGAOWIACorPayaV+h9X8wxhg/liCAbQeKKK/yWgsmY4zxYwmCL3tQWwsmY4z5UkgThIjMEJGtIrJDRO44znaXioiKyAS/ZXf69tsqIueGMs4MTz7xnSPpm9wllG9jjDGtSsjGtBaRCOAh4GzAA6wWkUWqmllru1jgVuATv2XDgTnACKAXsFxEBqtqdShiXZ/lOsiJSCgOb4wxrVIo7yAmAjtUdZeqVgDPAbMDbPdb4I9Amd+y2cBzqlquqruBHb7jBV1ZZTVbDxRZ/YMxxtQSygSRBmT5vfb4lh0jIuOA3qq6uKH7BktRWRXnj+rJqQNTQnF4Y4xptcI2bZqIdADuA65rwjHmAfMA+vTp06hjpMZ24oErxzY2BGOMabNCeQeRDfT2e53uW1YjFhgJrBKRPcBkYJGvovpE+wKgqo+q6gRVnZCamhrk8I0xpn0LZYJYDZwkIv1FJApX6byoZqWqFqhqiqr2U9V+wMfALFVd49tujoh0EpH+wEnApyGM1RhjTC0hK2JS1SoRuQV4C4gAFqjqJhGZD6xR1UXH2XeTiLwAZAJVwA9C1YLJGGNMYKKq4Y4hKCZMmKBr1qwJdxjGGNOqiMhaVZ0QaJ31pDbGGBOQJQhjjDEBWYIwxhgTkCUIY4wxAbWZSmoRyQX2NuEQKcChIIUTChZf01h8TWPxNU1Ljq+vqgbsSNZmEkRTiciaumryWwKLr2ksvqax+JqmpcdXFytiMsYYE5AlCGOMMQFZgvjSo+EO4AQsvqax+JrG4mualh5fQFYHYYwxJiC7gzDGGBOQJQhjjDEBtasEISIzRGSriOwQkTsCrO8kIs/71n8iIv2aMbbeIrJSRDJFZJOI3Bpgm2kiUiAi63yPu5srPr8Y9ojIBt/7f210RHEe8J3DDN+sgc0V2xC/c7NORApF5Me1tmnWcygiC0TkoIhs9FuWJCLLRGS779/EOva91rfNdhG5thnj+7OIbPH9/y0UkYQ69j3uZyGE8f1aRLL9/g/Pq2Pf437fQxjf836x7RGRdXXsG/Lz12Sq2i4euCHHdwIDgChgPTC81jbfBx72PZ8DPN+M8fUExvmexwLbAsQ3DXgjzOdxD5BynPXnAW8CgpsE6pMw/n/vx3UCCts5BM4AxgEb/Zb9CbjD9/wO4I8B9ksCdvn+TfQ9T2ym+M4BOvqe/zFQfPX5LIQwvl8D/1OP///jft9DFV+t9f8L3B2u89fUR3u6g5gI7FDVXapaATwHzK61zWzgCd/zl4DpIiLNEZyq5qjqZ77nRcBmQjQPd4jNBv6jzsdAgoj0DEMc04GdqtqU3vVNpqrvAodrLfb/nD0BXBRg13OBZap6WFWPAMuAGc0Rn6ouVdUq38uPcTM6hkUd568+6vN9b7Ljxee7dlwOPBvs920u7SlBpAFZfq89fP0CfGwb3xekAEhuluj8+Iq2xgKfBFg9RUTWi8ibIjKieSMDQIGlIrLWNyd4bfU5z81hDnV/McN9Drurao7v+X6ge4BtWsp5vB53RxjIiT4LoXSLrwhsQR1FdC3h/E0FDqjq9jrWh/P81Ut7ShCtgojEAC8DP1bVwlqrP8MVmZwMPAi82szhAZyuquOAmcAPROSMMMRwXOKmuJ0FvBhgdUs4h8eoK2tokW3NReQXuBkdn65jk3B9Fv4BDATGADm4YpyW6EqOf/fQ4r9L7SlBZAO9/V6n+5YF3EZEOgLxQF6zROfeMxKXHJ5W1Vdqr1fVQlUt9j1fAkSKSEpzxed732zfvweBhbhbeX/1Oc+hNhP4TFUP1F7REs4hcKCm2M3378EA24T1PIrIdcAFwLd9Sexr6vFZCAlVPaCq1arqBf5Zx/uG+/x1BC4Bnq9rm3Cdv4ZoTwliNXCSiPT3/cKcA9SeF3sRUNNa5DJgRV1fjmDzlVc+DmxW1fvq2KZHTZ2IiEzE/f81ZwLrKiKxNc9xlZkba222CLjG15ppMlDgV5zSXOr85Rbuc+jj/zm7FngtwDZvAeeISKKvCOUc37KQE5EZwM+AWap6tI5t6vNZCFV8/nVaF9fxvvX5vofSN4EtquoJtDKc569Bwl1L3pwPXAubbbjWDb/wLZuP+yIAROOKJXYAnwIDmjG203FFDRnAOt/jPOBm4GbfNrcAm3AtMj4GTm3m8zfA997rfXHUnEP/GAV4yHeONwATmjnGrrgLfrzfsrCdQ1yiygEqceXgN+Dqtd4GtgPLgSTfthOAx/z2vd73WdwBfKcZ49uBK7+v+RzWtOzrBSw53mehmeJ70vfZysBd9HvWjs/3+mvf9+aIz7f83zWfOb9tm/38NfVhQ20YY4wJqD0VMRljjGkASxDGGGMCsgRhjDEmIEsQxhhjArIEYYwxJiBLEMa0AL5RZt8IdxzG+LMEYYwxJiBLEMY0gIjMFZFPfWP4PyIiESJSLCL/J24ej7dFJNW37RgR+dhvXoVE3/JBIrLcN2DgZyIy0Hf4GBF5yTcXw9PNNZKwMXWxBGFMPYnIMOAK4DRVHQNUA9/G9d5eo6ojgHeAX/l2+Q9wu6qOxvX8rVn+NPCQugEDT8X1xAU3gu+PgeG4nranhfhPMua4OoY7AGNakenAeGC178d9Z9xAe16+HJTtKeAVEYkHElT1Hd/yJ4AXfePvpKnqQgBVLQPwHe9T9Y3d45uFrB/wfsj/KmPqYAnCmPoT4AlVvfMrC0V+WWu7xo5fU+73vBr7fpowsyImY+rvbeAyEekGx+aW7ov7Hl3m2+Yq4H1VLQCOiMhU3/KrgXfUzRboEZGLfMfoJCJdmvOPMKa+7BeKMfWkqpkichduFrAOuBE8fwCUABN96w7i6inADeX9sC8B7AK+41t+NfCIiMz3HeNbzfhnGFNvNpqrMU0kIsWqGhPuOIwJNitiMsYYE5DdQRhjjAnI7iCMMcYEZAnCGGNMQJYgjDHGBGQJwhhjTECWIIwxxgT0/wGua5dAwInPsQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_his.history['f1'])\n",
    "plt.plot(train_his.history['val_f1'])\n",
    "plt.title('model f1')\n",
    "plt.ylabel('f1')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1506/1506 [==============================] - 0s 263us/step\n"
     ]
    }
   ],
   "source": [
    "scores = train_model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Scores:\n",
      " loss of 1.1431685179115767; \n",
      " accuracy of 0.5949535369873047 ;\n",
      " precision_2 of 0.6406117081642151 ;\n",
      " recall_2 of 0.5006639957427979 ;\n",
      " f1 of 0.5632489323616028 ;\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"Evaluation Scores:\n",
    " {train_model.metrics_names[0]} of {scores[0]}; \n",
    " {train_model.metrics_names[1]} of {scores[1]} ;\n",
    " {train_model.metrics_names[2]} of {scores[2]} ;\n",
    " {train_model.metrics_names[3]} of {scores[3]} ;\n",
    " {train_model.metrics_names[4]} of {scores[4]} ;\n",
    " \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Do_Cross_Validation(X,y):\n",
    "\n",
    "  # Define per-fold score containers\n",
    "  loss_per_fold = []\n",
    "  acc_per_fold = []\n",
    "  precision_per_fold = []\n",
    "  recall_per_fold = []\n",
    "  f1_per_fold = []\n",
    "  \n",
    "\n",
    "  kfold = KFold(n_splits=FOLDS, shuffle=True)\n",
    "\n",
    "  fold_no = 1\n",
    "  inputs = X\n",
    "  targets = y\n",
    "  for train, test in kfold.split(inputs, targets):\n",
    "\n",
    "    model = RNN_model()\n",
    "\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    # Fit data to model\n",
    "    model, his = Train_Model(model,inputs[train], targets[train], cross_validation=True)\n",
    " \n",
    "    # Generate generalization metrics\n",
    "    scores = model.evaluate(inputs[test], targets[test], verbose=0)\n",
    "\n",
    "    print(f\"\"\"Score for fold {fold_no}:\n",
    "     {model.metrics_names[0]} of {scores[0]}; \n",
    "     {model.metrics_names[1]} of {scores[1]*100}% ;\n",
    "     {model.metrics_names[2]} of {scores[2]*100}% ;\n",
    "     {model.metrics_names[3]} of {scores[3]*100}% ;\n",
    "     {model.metrics_names[4]} of {scores[4]*100}% ;\n",
    "     \"\"\")\n",
    "    \n",
    "    loss_per_fold.append(scores[0])\n",
    "    acc_per_fold.append(scores[1])\n",
    "    precision_per_fold.append(scores[2])\n",
    "    recall_per_fold.append(scores[3])\n",
    "    f1_per_fold.append(scores[4])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "\n",
    "  # == Provide average scores ==\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print('Score per fold')\n",
    "  for i in range(0, len(acc_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f\"\"\"> Fold {i+1} - \n",
    "    Loss: {loss_per_fold[i]} - \n",
    "    Accuracy: {acc_per_fold[i]}% - \n",
    "    Precesion: {precision_per_fold[i]}% - \n",
    "    Recall: {recall_per_fold[i]}% - \n",
    "    F1: {f1_per_fold[i]}%\n",
    "    \"\"\")\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print('Average scores for all folds:')\n",
    "  print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "  print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "  print(f'> Precision: {np.mean(precision_per_fold)}')\n",
    "  print(f'> Recall: {np.mean(recall_per_fold)}')\n",
    "  print(f'> F1: {np.mean(f1_per_fold)}')\n",
    "  print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lahiru/anaconda3/envs/LASER-tf-1/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(32, activation=\"relu\", name=\"mlp\", kernel_initializer=\"he_normal\", kernel_constraint=<keras.con..., bias_constraint=<keras.con...)`\n",
      "  del sys.path[0]\n",
      "/home/lahiru/anaconda3/envs/LASER-tf-1/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, activation=\"softmax\", name=\"output\", kernel_initializer=\"he_normal\")`\n",
      "/home/lahiru/anaconda3/envs/LASER-tf-1/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `Model` call to the Keras 2 API: `Model(name=\"RNN_model\", inputs=Tensor(\"ma..., outputs=Tensor(\"ou...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"RNN_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "main_input (InputLayer)      (None, 64, 16)            0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 32)                6272      \n",
      "_________________________________________________________________\n",
      "mlp (Dense)                  (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "drop (Dropout)               (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 7,460\n",
      "Trainable params: 7,460\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Training and Testing...\n",
      "Epoch 1/15\n",
      "13553/13553 [==============================] - 13s 945us/step - loss: 1.1444 - accuracy: 0.5386 - precision_3: 0.6092 - recall_3: 0.3123 - f1: 0.4019\n",
      "Epoch 2/15\n",
      "13553/13553 [==============================] - 14s 1ms/step - loss: 1.0687 - accuracy: 0.5784 - precision_3: 0.6512 - recall_3: 0.4212 - f1: 0.5087\n",
      "Epoch 3/15\n",
      "13553/13553 [==============================] - 17s 1ms/step - loss: 1.0368 - accuracy: 0.5887 - precision_3: 0.6591 - recall_3: 0.4448 - f1: 0.5281\n",
      "Epoch 4/15\n",
      "13553/13553 [==============================] - 13s 931us/step - loss: 1.0174 - accuracy: 0.5974 - precision_3: 0.6720 - recall_3: 0.4617 - f1: 0.5454\n",
      "Epoch 5/15\n",
      "13553/13553 [==============================] - 13s 973us/step - loss: 1.0018 - accuracy: 0.6042 - precision_3: 0.6776 - recall_3: 0.4693 - f1: 0.5523\n",
      "Epoch 6/15\n",
      "13553/13553 [==============================] - 12s 863us/step - loss: 0.9812 - accuracy: 0.6098 - precision_3: 0.6907 - recall_3: 0.4784 - f1: 0.5631\n",
      "Epoch 7/15\n",
      "13553/13553 [==============================] - 12s 909us/step - loss: 0.9666 - accuracy: 0.6179 - precision_3: 0.6952 - recall_3: 0.4899 - f1: 0.5724\n",
      "Epoch 8/15\n",
      "13553/13553 [==============================] - 12s 851us/step - loss: 0.9494 - accuracy: 0.6230 - precision_3: 0.7006 - recall_3: 0.4998 - f1: 0.5813\n",
      "Epoch 9/15\n",
      "13553/13553 [==============================] - 13s 925us/step - loss: 0.9390 - accuracy: 0.6247 - precision_3: 0.7031 - recall_3: 0.5010 - f1: 0.5825\n",
      "Epoch 10/15\n",
      "13553/13553 [==============================] - 14s 999us/step - loss: 0.9283 - accuracy: 0.6311 - precision_3: 0.7082 - recall_3: 0.5132 - f1: 0.5929\n",
      "Epoch 11/15\n",
      "13553/13553 [==============================] - 13s 964us/step - loss: 0.9152 - accuracy: 0.6372 - precision_3: 0.7155 - recall_3: 0.5206 - f1: 0.6013\n",
      "Epoch 12/15\n",
      "13553/13553 [==============================] - 12s 905us/step - loss: 0.9006 - accuracy: 0.6416 - precision_3: 0.7167 - recall_3: 0.5308 - f1: 0.6083\n",
      "Epoch 13/15\n",
      "13553/13553 [==============================] - 12s 872us/step - loss: 0.8913 - accuracy: 0.6445 - precision_3: 0.7203 - recall_3: 0.5380 - f1: 0.6145\n",
      "Epoch 14/15\n",
      "13553/13553 [==============================] - 14s 1ms/step - loss: 0.8765 - accuracy: 0.6525 - precision_3: 0.7203 - recall_3: 0.5464 - f1: 0.6200\n",
      "Epoch 15/15\n",
      "13553/13553 [==============================] - 15s 1ms/step - loss: 0.8676 - accuracy: 0.6560 - precision_3: 0.7324 - recall_3: 0.5520 - f1: 0.6280\n",
      "Score for fold 1:\n",
      "     loss of 1.1532501062232343; \n",
      "     accuracy of 58.831340074539185% ;\n",
      "     precision_3 of 62.96900510787964% ;\n",
      "     recall_3 of 51.261621713638306% ;\n",
      "     f1 of 56.280285120010376% ;\n",
      "     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lahiru/anaconda3/envs/LASER-tf-1/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(32, activation=\"relu\", name=\"mlp\", kernel_initializer=\"he_normal\", kernel_constraint=<keras.con..., bias_constraint=<keras.con...)`\n",
      "  del sys.path[0]\n",
      "/home/lahiru/anaconda3/envs/LASER-tf-1/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, activation=\"softmax\", name=\"output\", kernel_initializer=\"he_normal\")`\n",
      "/home/lahiru/anaconda3/envs/LASER-tf-1/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `Model` call to the Keras 2 API: `Model(name=\"RNN_model\", inputs=Tensor(\"ma..., outputs=Tensor(\"ou...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"RNN_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "main_input (InputLayer)      (None, 64, 16)            0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 32)                6272      \n",
      "_________________________________________________________________\n",
      "mlp (Dense)                  (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "drop (Dropout)               (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 7,460\n",
      "Trainable params: 7,460\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Training and Testing...\n",
      "Epoch 1/15\n",
      "13553/13553 [==============================] - 14s 1ms/step - loss: 1.1407 - accuracy: 0.5418 - precision_4: 0.6216 - recall_4: 0.3200 - f1: 0.4115\n",
      "Epoch 2/15\n",
      "13553/13553 [==============================] - 12s 873us/step - loss: 1.0689 - accuracy: 0.5750 - precision_4: 0.6469 - recall_4: 0.4090 - f1: 0.4983\n",
      "Epoch 3/15\n",
      "13553/13553 [==============================] - 14s 1ms/step - loss: 1.0398 - accuracy: 0.5872 - precision_4: 0.6585 - recall_4: 0.4431 - f1: 0.5274\n",
      "Epoch 4/15\n",
      "13553/13553 [==============================] - 15s 1ms/step - loss: 1.0195 - accuracy: 0.5985 - precision_4: 0.6674 - recall_4: 0.4537 - f1: 0.5372\n",
      "Epoch 5/15\n",
      "13553/13553 [==============================] - 14s 1ms/step - loss: 1.0019 - accuracy: 0.5999 - precision_4: 0.6703 - recall_4: 0.4799 - f1: 0.5569\n",
      "Epoch 6/15\n",
      "13553/13553 [==============================] - 14s 1ms/step - loss: 0.9863 - accuracy: 0.6075 - precision_4: 0.6766 - recall_4: 0.4843 - f1: 0.5628\n",
      "Epoch 7/15\n",
      "13553/13553 [==============================] - 14s 1ms/step - loss: 0.9725 - accuracy: 0.6133 - precision_4: 0.6809 - recall_4: 0.4925 - f1: 0.5700\n",
      "Epoch 8/15\n",
      "13553/13553 [==============================] - 17s 1ms/step - loss: 0.9624 - accuracy: 0.6149 - precision_4: 0.6889 - recall_4: 0.5008 - f1: 0.5780\n",
      "Epoch 9/15\n",
      "13553/13553 [==============================] - 13s 993us/step - loss: 0.9464 - accuracy: 0.6209 - precision_4: 0.6937 - recall_4: 0.5105 - f1: 0.5861\n",
      "Epoch 10/15\n",
      "13553/13553 [==============================] - 12s 882us/step - loss: 0.9348 - accuracy: 0.6267 - precision_4: 0.6965 - recall_4: 0.5267 - f1: 0.5978\n",
      "Epoch 11/15\n",
      "13553/13553 [==============================] - 11s 823us/step - loss: 0.9249 - accuracy: 0.6342 - precision_4: 0.6962 - recall_4: 0.5300 - f1: 0.6003\n",
      "Epoch 12/15\n",
      "13553/13553 [==============================] - 13s 957us/step - loss: 0.9089 - accuracy: 0.6357 - precision_4: 0.7051 - recall_4: 0.5377 - f1: 0.6088\n",
      "Epoch 13/15\n",
      "13553/13553 [==============================] - 12s 861us/step - loss: 0.9014 - accuracy: 0.6384 - precision_4: 0.7028 - recall_4: 0.5380 - f1: 0.6078\n",
      "Epoch 14/15\n",
      "13553/13553 [==============================] - 12s 901us/step - loss: 0.8841 - accuracy: 0.6469 - precision_4: 0.7071 - recall_4: 0.5502 - f1: 0.6173\n",
      "Epoch 15/15\n",
      "13553/13553 [==============================] - 13s 932us/step - loss: 0.8679 - accuracy: 0.6548 - precision_4: 0.7181 - recall_4: 0.5580 - f1: 0.6265\n",
      "Score for fold 2:\n",
      "     loss of 1.0578877278374803; \n",
      "     accuracy of 60.29216647148132% ;\n",
      "     precision_4 of 65.54403901100159% ;\n",
      "     recall_4 of 50.39840340614319% ;\n",
      "     f1 of 56.6886842250824% ;\n",
      "     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lahiru/anaconda3/envs/LASER-tf-1/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(32, activation=\"relu\", name=\"mlp\", kernel_initializer=\"he_normal\", kernel_constraint=<keras.con..., bias_constraint=<keras.con...)`\n",
      "  del sys.path[0]\n",
      "/home/lahiru/anaconda3/envs/LASER-tf-1/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, activation=\"softmax\", name=\"output\", kernel_initializer=\"he_normal\")`\n",
      "/home/lahiru/anaconda3/envs/LASER-tf-1/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `Model` call to the Keras 2 API: `Model(name=\"RNN_model\", inputs=Tensor(\"ma..., outputs=Tensor(\"ou...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"RNN_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "main_input (InputLayer)      (None, 64, 16)            0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 32)                6272      \n",
      "_________________________________________________________________\n",
      "mlp (Dense)                  (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "drop (Dropout)               (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 7,460\n",
      "Trainable params: 7,460\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Training and Testing...\n",
      "Epoch 1/15\n",
      "13553/13553 [==============================] - 13s 923us/step - loss: 1.1485 - accuracy: 0.5399 - precision_5: 0.6118 - recall_5: 0.3033 - f1: 0.3959\n",
      "Epoch 2/15\n",
      "13553/13553 [==============================] - 13s 941us/step - loss: 1.0792 - accuracy: 0.5718 - precision_5: 0.6384 - recall_5: 0.4087 - f1: 0.4955\n",
      "Epoch 3/15\n",
      "13553/13553 [==============================] - 12s 865us/step - loss: 1.0381 - accuracy: 0.5876 - precision_5: 0.6551 - recall_5: 0.4448 - f1: 0.5268\n",
      "Epoch 4/15\n",
      "13553/13553 [==============================] - 11s 830us/step - loss: 1.0145 - accuracy: 0.5957 - precision_5: 0.6662 - recall_5: 0.4727 - f1: 0.5507\n",
      "Epoch 5/15\n",
      "13553/13553 [==============================] - 12s 857us/step - loss: 0.9975 - accuracy: 0.6039 - precision_5: 0.6713 - recall_5: 0.4845 - f1: 0.5611\n",
      "Epoch 6/15\n",
      "13553/13553 [==============================] - 11s 824us/step - loss: 0.9761 - accuracy: 0.6125 - precision_5: 0.6801 - recall_5: 0.4947 - f1: 0.5711\n",
      "Epoch 7/15\n",
      "13553/13553 [==============================] - 12s 882us/step - loss: 0.9670 - accuracy: 0.6157 - precision_5: 0.6810 - recall_5: 0.5085 - f1: 0.5805\n",
      "Epoch 8/15\n",
      "13553/13553 [==============================] - 12s 849us/step - loss: 0.9545 - accuracy: 0.6188 - precision_5: 0.6868 - recall_5: 0.5170 - f1: 0.5882\n",
      "Epoch 9/15\n",
      "13553/13553 [==============================] - 11s 800us/step - loss: 0.9398 - accuracy: 0.6258 - precision_5: 0.7013 - recall_5: 0.5242 - f1: 0.5975\n",
      "Epoch 10/15\n",
      "13553/13553 [==============================] - 11s 802us/step - loss: 0.9244 - accuracy: 0.6328 - precision_5: 0.7005 - recall_5: 0.5342 - f1: 0.6044\n",
      "Epoch 11/15\n",
      "13553/13553 [==============================] - 12s 917us/step - loss: 0.9155 - accuracy: 0.6370 - precision_5: 0.7038 - recall_5: 0.5386 - f1: 0.6088\n",
      "Epoch 12/15\n",
      "13553/13553 [==============================] - 11s 801us/step - loss: 0.9024 - accuracy: 0.6390 - precision_5: 0.7034 - recall_5: 0.5485 - f1: 0.6146\n",
      "Epoch 13/15\n",
      "13553/13553 [==============================] - 11s 839us/step - loss: 0.8848 - accuracy: 0.6491 - precision_5: 0.7124 - recall_5: 0.5577 - f1: 0.6240\n",
      "Epoch 14/15\n",
      "13553/13553 [==============================] - 11s 828us/step - loss: 0.8727 - accuracy: 0.6522 - precision_5: 0.7157 - recall_5: 0.5652 - f1: 0.6304\n",
      "Epoch 15/15\n",
      "13553/13553 [==============================] - 11s 815us/step - loss: 0.8660 - accuracy: 0.6568 - precision_5: 0.7195 - recall_5: 0.5723 - f1: 0.6361\n",
      "Score for fold 3:\n",
      "     loss of 1.1079763001496414; \n",
      "     accuracy of 59.0969443321228% ;\n",
      "     precision_5 of 63.14021944999695% ;\n",
      "     recall_5 of 49.933600425720215% ;\n",
      "     f1 of 54.530054330825806% ;\n",
      "     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lahiru/anaconda3/envs/LASER-tf-1/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(32, activation=\"relu\", name=\"mlp\", kernel_initializer=\"he_normal\", kernel_constraint=<keras.con..., bias_constraint=<keras.con...)`\n",
      "  del sys.path[0]\n",
      "/home/lahiru/anaconda3/envs/LASER-tf-1/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, activation=\"softmax\", name=\"output\", kernel_initializer=\"he_normal\")`\n",
      "/home/lahiru/anaconda3/envs/LASER-tf-1/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `Model` call to the Keras 2 API: `Model(name=\"RNN_model\", inputs=Tensor(\"ma..., outputs=Tensor(\"ou...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"RNN_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "main_input (InputLayer)      (None, 64, 16)            0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 32)                6272      \n",
      "_________________________________________________________________\n",
      "mlp (Dense)                  (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "drop (Dropout)               (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 7,460\n",
      "Trainable params: 7,460\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Training and Testing...\n",
      "Epoch 1/15\n",
      "13553/13553 [==============================] - 11s 844us/step - loss: 1.1546 - accuracy: 0.5376 - precision_6: 0.6102 - recall_6: 0.2975 - f1: 0.3892\n",
      "Epoch 2/15\n",
      "13553/13553 [==============================] - 11s 840us/step - loss: 1.0742 - accuracy: 0.5733 - precision_6: 0.6370 - recall_6: 0.4041 - f1: 0.4913\n",
      "Epoch 3/15\n",
      "13553/13553 [==============================] - 13s 935us/step - loss: 1.0424 - accuracy: 0.5837 - precision_6: 0.6552 - recall_6: 0.4440 - f1: 0.5270\n",
      "Epoch 4/15\n",
      "13553/13553 [==============================] - 11s 809us/step - loss: 1.0232 - accuracy: 0.5940 - precision_6: 0.6624 - recall_6: 0.4583 - f1: 0.5401\n",
      "Epoch 5/15\n",
      "13553/13553 [==============================] - 11s 810us/step - loss: 1.0004 - accuracy: 0.6029 - precision_6: 0.6721 - recall_6: 0.4824 - f1: 0.5599\n",
      "Epoch 6/15\n",
      "13553/13553 [==============================] - 11s 806us/step - loss: 0.9879 - accuracy: 0.6090 - precision_6: 0.6723 - recall_6: 0.4907 - f1: 0.5653\n",
      "Epoch 7/15\n",
      "13553/13553 [==============================] - 11s 805us/step - loss: 0.9698 - accuracy: 0.6142 - precision_6: 0.6817 - recall_6: 0.5061 - f1: 0.5793\n",
      "Epoch 8/15\n",
      "13553/13553 [==============================] - 11s 810us/step - loss: 0.9588 - accuracy: 0.6175 - precision_6: 0.6827 - recall_6: 0.5148 - f1: 0.5854\n",
      "Epoch 9/15\n",
      "13553/13553 [==============================] - 12s 855us/step - loss: 0.9453 - accuracy: 0.6237 - precision_6: 0.6851 - recall_6: 0.5201 - f1: 0.5896\n",
      "Epoch 10/15\n",
      "13553/13553 [==============================] - 13s 936us/step - loss: 0.9354 - accuracy: 0.6317 - precision_6: 0.6957 - recall_6: 0.5274 - f1: 0.5981\n",
      "Epoch 11/15\n",
      "13553/13553 [==============================] - 12s 862us/step - loss: 0.9215 - accuracy: 0.6328 - precision_6: 0.6928 - recall_6: 0.5354 - f1: 0.6028\n",
      "Epoch 12/15\n",
      "13553/13553 [==============================] - 11s 814us/step - loss: 0.9096 - accuracy: 0.6354 - precision_6: 0.6970 - recall_6: 0.5415 - f1: 0.6084\n",
      "Epoch 13/15\n",
      "13553/13553 [==============================] - 12s 913us/step - loss: 0.8986 - accuracy: 0.6389 - precision_6: 0.7058 - recall_6: 0.5439 - f1: 0.6132\n",
      "Epoch 14/15\n",
      "13553/13553 [==============================] - 13s 951us/step - loss: 0.8887 - accuracy: 0.6448 - precision_6: 0.7069 - recall_6: 0.5478 - f1: 0.6155\n",
      "Epoch 15/15\n",
      "13553/13553 [==============================] - 11s 814us/step - loss: 0.8772 - accuracy: 0.6475 - precision_6: 0.7111 - recall_6: 0.5560 - f1: 0.6228\n",
      "Score for fold 4:\n",
      "     loss of 1.0554572842510572; \n",
      "     accuracy of 61.6865873336792% ;\n",
      "     precision_6 of 66.88796877861023% ;\n",
      "     recall_6 of 53.51925492286682% ;\n",
      "     f1 of 59.22269821166992% ;\n",
      "     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lahiru/anaconda3/envs/LASER-tf-1/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(32, activation=\"relu\", name=\"mlp\", kernel_initializer=\"he_normal\", kernel_constraint=<keras.con..., bias_constraint=<keras.con...)`\n",
      "  del sys.path[0]\n",
      "/home/lahiru/anaconda3/envs/LASER-tf-1/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, activation=\"softmax\", name=\"output\", kernel_initializer=\"he_normal\")`\n",
      "/home/lahiru/anaconda3/envs/LASER-tf-1/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `Model` call to the Keras 2 API: `Model(name=\"RNN_model\", inputs=Tensor(\"ma..., outputs=Tensor(\"ou...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"RNN_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "main_input (InputLayer)      (None, 64, 16)            0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 32)                6272      \n",
      "_________________________________________________________________\n",
      "mlp (Dense)                  (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "drop (Dropout)               (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 7,460\n",
      "Trainable params: 7,460\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Training and Testing...\n",
      "Epoch 1/15\n",
      "13553/13553 [==============================] - 13s 934us/step - loss: 1.1493 - accuracy: 0.5400 - precision_7: 0.6063 - recall_7: 0.3086 - f1: 0.4013\n",
      "Epoch 2/15\n",
      "13553/13553 [==============================] - 13s 941us/step - loss: 1.0725 - accuracy: 0.5737 - precision_7: 0.6424 - recall_7: 0.4082 - f1: 0.4953\n",
      "Epoch 3/15\n",
      "13553/13553 [==============================] - 12s 922us/step - loss: 1.0381 - accuracy: 0.5878 - precision_7: 0.6563 - recall_7: 0.4457 - f1: 0.5282\n",
      "Epoch 4/15\n",
      "13553/13553 [==============================] - 11s 827us/step - loss: 1.0210 - accuracy: 0.5940 - precision_7: 0.6629 - recall_7: 0.4644 - f1: 0.5437\n",
      "Epoch 5/15\n",
      "13553/13553 [==============================] - 11s 843us/step - loss: 0.9994 - accuracy: 0.6055 - precision_7: 0.6713 - recall_7: 0.4800 - f1: 0.5583\n",
      "Epoch 6/15\n",
      "13553/13553 [==============================] - 13s 989us/step - loss: 0.9872 - accuracy: 0.6100 - precision_7: 0.6769 - recall_7: 0.4892 - f1: 0.5658\n",
      "Epoch 7/15\n",
      "13553/13553 [==============================] - 12s 922us/step - loss: 0.9666 - accuracy: 0.6166 - precision_7: 0.6801 - recall_7: 0.5009 - f1: 0.5754\n",
      "Epoch 8/15\n",
      "13553/13553 [==============================] - 11s 841us/step - loss: 0.9563 - accuracy: 0.6224 - precision_7: 0.6873 - recall_7: 0.5150 - f1: 0.5869\n",
      "Epoch 9/15\n",
      "13553/13553 [==============================] - 11s 842us/step - loss: 0.9395 - accuracy: 0.6288 - precision_7: 0.6918 - recall_7: 0.5261 - f1: 0.5961\n",
      "Epoch 10/15\n",
      "13553/13553 [==============================] - 13s 925us/step - loss: 0.9258 - accuracy: 0.6321 - precision_7: 0.6994 - recall_7: 0.5319 - f1: 0.6026\n",
      "Epoch 11/15\n",
      "13553/13553 [==============================] - 12s 866us/step - loss: 0.9119 - accuracy: 0.6389 - precision_7: 0.7002 - recall_7: 0.5439 - f1: 0.6109\n",
      "Epoch 12/15\n",
      "13553/13553 [==============================] - 12s 919us/step - loss: 0.9024 - accuracy: 0.6414 - precision_7: 0.7042 - recall_7: 0.5455 - f1: 0.6134\n",
      "Epoch 13/15\n",
      "13553/13553 [==============================] - 12s 895us/step - loss: 0.8875 - accuracy: 0.6479 - precision_7: 0.7131 - recall_7: 0.5524 - f1: 0.6213\n",
      "Epoch 14/15\n",
      "13553/13553 [==============================] - 12s 869us/step - loss: 0.8779 - accuracy: 0.6506 - precision_7: 0.7100 - recall_7: 0.5600 - f1: 0.6249\n",
      "Epoch 15/15\n",
      "13553/13553 [==============================] - 12s 916us/step - loss: 0.8695 - accuracy: 0.6516 - precision_7: 0.7176 - recall_7: 0.5623 - f1: 0.6293\n",
      "Score for fold 5:\n",
      "     loss of 1.0784010602183551; \n",
      "     accuracy of 59.36254858970642% ;\n",
      "     precision_7 of 64.79400992393494% ;\n",
      "     recall_7 of 45.94953656196594% ;\n",
      "     f1 of 52.595287561416626% ;\n",
      "     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lahiru/anaconda3/envs/LASER-tf-1/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(32, activation=\"relu\", name=\"mlp\", kernel_initializer=\"he_normal\", kernel_constraint=<keras.con..., bias_constraint=<keras.con...)`\n",
      "  del sys.path[0]\n",
      "/home/lahiru/anaconda3/envs/LASER-tf-1/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, activation=\"softmax\", name=\"output\", kernel_initializer=\"he_normal\")`\n",
      "/home/lahiru/anaconda3/envs/LASER-tf-1/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `Model` call to the Keras 2 API: `Model(name=\"RNN_model\", inputs=Tensor(\"ma..., outputs=Tensor(\"ou...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"RNN_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "main_input (InputLayer)      (None, 64, 16)            0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 32)                6272      \n",
      "_________________________________________________________________\n",
      "mlp (Dense)                  (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "drop (Dropout)               (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 7,460\n",
      "Trainable params: 7,460\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "Training and Testing...\n",
      "Epoch 1/15\n",
      "13553/13553 [==============================] - 12s 898us/step - loss: 1.1537 - accuracy: 0.5322 - precision_8: 0.6067 - recall_8: 0.3032 - f1: 0.3942\n",
      "Epoch 2/15\n",
      "13553/13553 [==============================] - 11s 821us/step - loss: 1.0811 - accuracy: 0.5684 - precision_8: 0.6464 - recall_8: 0.3928 - f1: 0.4846\n",
      "Epoch 3/15\n",
      "13553/13553 [==============================] - 12s 904us/step - loss: 1.0485 - accuracy: 0.5813 - precision_8: 0.6552 - recall_8: 0.4304 - f1: 0.5163\n",
      "Epoch 4/15\n",
      "13553/13553 [==============================] - 12s 871us/step - loss: 1.0253 - accuracy: 0.5927 - precision_8: 0.6659 - recall_8: 0.4552 - f1: 0.5386\n",
      "Epoch 5/15\n",
      "13553/13553 [==============================] - 12s 913us/step - loss: 1.0081 - accuracy: 0.5993 - precision_8: 0.6749 - recall_8: 0.4736 - f1: 0.5546\n",
      "Epoch 6/15\n",
      "13553/13553 [==============================] - 12s 854us/step - loss: 0.9942 - accuracy: 0.6067 - precision_8: 0.6797 - recall_8: 0.4847 - f1: 0.5642\n",
      "Epoch 7/15\n",
      "13553/13553 [==============================] - 13s 968us/step - loss: 0.9755 - accuracy: 0.6124 - precision_8: 0.6869 - recall_8: 0.4894 - f1: 0.5700\n",
      "Epoch 8/15\n",
      "13553/13553 [==============================] - 14s 1ms/step - loss: 0.9677 - accuracy: 0.6167 - precision_8: 0.6910 - recall_8: 0.5027 - f1: 0.5802\n",
      "Epoch 9/15\n",
      "13553/13553 [==============================] - 18s 1ms/step - loss: 0.9514 - accuracy: 0.6232 - precision_8: 0.6899 - recall_8: 0.5110 - f1: 0.5852\n",
      "Epoch 10/15\n",
      "13553/13553 [==============================] - 17s 1ms/step - loss: 0.9354 - accuracy: 0.6266 - precision_8: 0.7006 - recall_8: 0.5214 - f1: 0.5961\n",
      "Epoch 11/15\n",
      "13553/13553 [==============================] - 13s 939us/step - loss: 0.9253 - accuracy: 0.6335 - precision_8: 0.7054 - recall_8: 0.5256 - f1: 0.6004\n",
      "Epoch 12/15\n",
      "13553/13553 [==============================] - 14s 1ms/step - loss: 0.9121 - accuracy: 0.6383 - precision_8: 0.7120 - recall_8: 0.5295 - f1: 0.6056\n",
      "Epoch 13/15\n",
      "13553/13553 [==============================] - 14s 1ms/step - loss: 0.8980 - accuracy: 0.6406 - precision_8: 0.7158 - recall_8: 0.5366 - f1: 0.6114\n",
      "Epoch 14/15\n",
      "13553/13553 [==============================] - 13s 983us/step - loss: 0.8845 - accuracy: 0.6448 - precision_8: 0.7234 - recall_8: 0.5445 - f1: 0.6195\n",
      "Epoch 15/15\n",
      "13553/13553 [==============================] - 12s 879us/step - loss: 0.8738 - accuracy: 0.6498 - precision_8: 0.7280 - recall_8: 0.5424 - f1: 0.6199\n",
      "Score for fold 6:\n",
      "     loss of 1.0389764961176817; \n",
      "     accuracy of 59.76095795631409% ;\n",
      "     precision_8 of 65.56939482688904% ;\n",
      "     recall_8 of 48.93758296966553% ;\n",
      "     f1 of 56.71623349189758% ;\n",
      "     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lahiru/anaconda3/envs/LASER-tf-1/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(32, activation=\"relu\", name=\"mlp\", kernel_initializer=\"he_normal\", kernel_constraint=<keras.con..., bias_constraint=<keras.con...)`\n",
      "  del sys.path[0]\n",
      "/home/lahiru/anaconda3/envs/LASER-tf-1/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, activation=\"softmax\", name=\"output\", kernel_initializer=\"he_normal\")`\n",
      "/home/lahiru/anaconda3/envs/LASER-tf-1/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `Model` call to the Keras 2 API: `Model(name=\"RNN_model\", inputs=Tensor(\"ma..., outputs=Tensor(\"ou...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"RNN_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "main_input (InputLayer)      (None, 64, 16)            0         \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 32)                6272      \n",
      "_________________________________________________________________\n",
      "mlp (Dense)                  (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "drop (Dropout)               (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 7,460\n",
      "Trainable params: 7,460\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "Training and Testing...\n",
      "Epoch 1/15\n",
      "13553/13553 [==============================] - 11s 846us/step - loss: 1.1469 - accuracy: 0.5421 - precision_9: 0.6114 - recall_9: 0.3099 - f1: 0.4007\n",
      "Epoch 2/15\n",
      "13553/13553 [==============================] - 11s 832us/step - loss: 1.0597 - accuracy: 0.5785 - precision_9: 0.6492 - recall_9: 0.4197 - f1: 0.5069\n",
      "Epoch 3/15\n",
      "13553/13553 [==============================] - 11s 815us/step - loss: 1.0307 - accuracy: 0.5925 - precision_9: 0.6595 - recall_9: 0.4541 - f1: 0.5352\n",
      "Epoch 4/15\n",
      "13553/13553 [==============================] - 12s 851us/step - loss: 1.0105 - accuracy: 0.6008 - precision_9: 0.6707 - recall_9: 0.4796 - f1: 0.5570\n",
      "Epoch 5/15\n",
      "13553/13553 [==============================] - 11s 825us/step - loss: 0.9920 - accuracy: 0.6109 - precision_9: 0.6783 - recall_9: 0.4923 - f1: 0.5684\n",
      "Epoch 6/15\n",
      "13553/13553 [==============================] - 12s 886us/step - loss: 0.9797 - accuracy: 0.6132 - precision_9: 0.6812 - recall_9: 0.4978 - f1: 0.5729\n",
      "Epoch 7/15\n",
      "13553/13553 [==============================] - 11s 839us/step - loss: 0.9664 - accuracy: 0.6202 - precision_9: 0.6836 - recall_9: 0.5126 - f1: 0.5843\n",
      "Epoch 8/15\n",
      "13553/13553 [==============================] - 11s 836us/step - loss: 0.9549 - accuracy: 0.6242 - precision_9: 0.6859 - recall_9: 0.5268 - f1: 0.5942\n",
      "Epoch 9/15\n",
      "13553/13553 [==============================] - 11s 848us/step - loss: 0.9414 - accuracy: 0.6257 - precision_9: 0.6915 - recall_9: 0.5327 - f1: 0.6005\n",
      "Epoch 10/15\n",
      "13553/13553 [==============================] - 11s 839us/step - loss: 0.9299 - accuracy: 0.6326 - precision_9: 0.6946 - recall_9: 0.5400 - f1: 0.6061\n",
      "Epoch 11/15\n",
      "13553/13553 [==============================] - 13s 945us/step - loss: 0.9171 - accuracy: 0.6376 - precision_9: 0.7021 - recall_9: 0.5431 - f1: 0.6109\n",
      "Epoch 12/15\n",
      "13553/13553 [==============================] - 13s 950us/step - loss: 0.9000 - accuracy: 0.6428 - precision_9: 0.7082 - recall_9: 0.5512 - f1: 0.6184\n",
      "Epoch 13/15\n",
      "13553/13553 [==============================] - 12s 906us/step - loss: 0.8952 - accuracy: 0.6423 - precision_9: 0.7078 - recall_9: 0.5495 - f1: 0.6171\n",
      "Epoch 14/15\n",
      "13553/13553 [==============================] - 11s 842us/step - loss: 0.8792 - accuracy: 0.6515 - precision_9: 0.7108 - recall_9: 0.5630 - f1: 0.6267\n",
      "Epoch 15/15\n",
      "13553/13553 [==============================] - 11s 841us/step - loss: 0.8683 - accuracy: 0.6557 - precision_9: 0.7166 - recall_9: 0.5693 - f1: 0.6332\n",
      "Score for fold 7:\n",
      "     loss of 1.1758659440049455; \n",
      "     accuracy of 58.698540925979614% ;\n",
      "     precision_9 of 62.59168982505798% ;\n",
      "     recall_9 of 50.99601745605469% ;\n",
      "     f1 of 55.76408505439758% ;\n",
      "     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lahiru/anaconda3/envs/LASER-tf-1/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(32, activation=\"relu\", name=\"mlp\", kernel_initializer=\"he_normal\", kernel_constraint=<keras.con..., bias_constraint=<keras.con...)`\n",
      "  del sys.path[0]\n",
      "/home/lahiru/anaconda3/envs/LASER-tf-1/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, activation=\"softmax\", name=\"output\", kernel_initializer=\"he_normal\")`\n",
      "/home/lahiru/anaconda3/envs/LASER-tf-1/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `Model` call to the Keras 2 API: `Model(name=\"RNN_model\", inputs=Tensor(\"ma..., outputs=Tensor(\"ou...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"RNN_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "main_input (InputLayer)      (None, 64, 16)            0         \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 32)                6272      \n",
      "_________________________________________________________________\n",
      "mlp (Dense)                  (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "drop (Dropout)               (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 7,460\n",
      "Trainable params: 7,460\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "Training and Testing...\n",
      "Epoch 1/15\n",
      "13553/13553 [==============================] - 12s 868us/step - loss: 1.1431 - accuracy: 0.5476 - precision_10: 0.6042 - recall_10: 0.3150 - f1: 0.4050\n",
      "Epoch 2/15\n",
      "13553/13553 [==============================] - 11s 814us/step - loss: 1.0672 - accuracy: 0.5780 - precision_10: 0.6439 - recall_10: 0.4159 - f1: 0.5019\n",
      "Epoch 3/15\n",
      "13553/13553 [==============================] - 11s 813us/step - loss: 1.0413 - accuracy: 0.5886 - precision_10: 0.6576 - recall_10: 0.4489 - f1: 0.5312\n",
      "Epoch 4/15\n",
      "13553/13553 [==============================] - 11s 814us/step - loss: 1.0132 - accuracy: 0.6009 - precision_10: 0.6683 - recall_10: 0.4701 - f1: 0.5498\n",
      "Epoch 5/15\n",
      "13553/13553 [==============================] - 11s 813us/step - loss: 1.0011 - accuracy: 0.6005 - precision_10: 0.6687 - recall_10: 0.4779 - f1: 0.5557\n",
      "Epoch 6/15\n",
      "13553/13553 [==============================] - 12s 891us/step - loss: 0.9857 - accuracy: 0.6076 - precision_10: 0.6783 - recall_10: 0.4843 - f1: 0.5635\n",
      "Epoch 7/15\n",
      "13553/13553 [==============================] - 11s 825us/step - loss: 0.9736 - accuracy: 0.6090 - precision_10: 0.6859 - recall_10: 0.4932 - f1: 0.5719\n",
      "Epoch 8/15\n",
      "13553/13553 [==============================] - 11s 835us/step - loss: 0.9586 - accuracy: 0.6195 - precision_10: 0.6903 - recall_10: 0.5031 - f1: 0.5801\n",
      "Epoch 9/15\n",
      "13553/13553 [==============================] - 11s 846us/step - loss: 0.9470 - accuracy: 0.6207 - precision_10: 0.6919 - recall_10: 0.5146 - f1: 0.5885\n",
      "Epoch 10/15\n",
      "13553/13553 [==============================] - 11s 838us/step - loss: 0.9308 - accuracy: 0.6253 - precision_10: 0.6960 - recall_10: 0.5220 - f1: 0.5947\n",
      "Epoch 11/15\n",
      "13553/13553 [==============================] - 12s 905us/step - loss: 0.9227 - accuracy: 0.6293 - precision_10: 0.6989 - recall_10: 0.5193 - f1: 0.5939\n",
      "Epoch 12/15\n",
      "13553/13553 [==============================] - 11s 844us/step - loss: 0.9156 - accuracy: 0.6337 - precision_10: 0.7036 - recall_10: 0.5293 - f1: 0.6024\n",
      "Epoch 13/15\n",
      "13553/13553 [==============================] - 11s 825us/step - loss: 0.9002 - accuracy: 0.6382 - precision_10: 0.7113 - recall_10: 0.5355 - f1: 0.6094\n",
      "Epoch 14/15\n",
      "13553/13553 [==============================] - 11s 842us/step - loss: 0.8873 - accuracy: 0.6430 - precision_10: 0.7134 - recall_10: 0.5372 - f1: 0.6110\n",
      "Epoch 15/15\n",
      "13553/13553 [==============================] - 11s 824us/step - loss: 0.8780 - accuracy: 0.6472 - precision_10: 0.7159 - recall_10: 0.5441 - f1: 0.6167\n",
      "Score for fold 8:\n",
      "     loss of 1.0591538824724802; \n",
      "     accuracy of 60.35856604576111% ;\n",
      "     precision_10 of 66.03284478187561% ;\n",
      "     recall_10 of 50.73041319847107% ;\n",
      "     f1 of 57.42024779319763% ;\n",
      "     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lahiru/anaconda3/envs/LASER-tf-1/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(32, activation=\"relu\", name=\"mlp\", kernel_initializer=\"he_normal\", kernel_constraint=<keras.con..., bias_constraint=<keras.con...)`\n",
      "  del sys.path[0]\n",
      "/home/lahiru/anaconda3/envs/LASER-tf-1/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, activation=\"softmax\", name=\"output\", kernel_initializer=\"he_normal\")`\n",
      "/home/lahiru/anaconda3/envs/LASER-tf-1/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `Model` call to the Keras 2 API: `Model(name=\"RNN_model\", inputs=Tensor(\"ma..., outputs=Tensor(\"ou...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"RNN_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "main_input (InputLayer)      (None, 64, 16)            0         \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 32)                6272      \n",
      "_________________________________________________________________\n",
      "mlp (Dense)                  (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "drop (Dropout)               (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 7,460\n",
      "Trainable params: 7,460\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "Training and Testing...\n",
      "Epoch 1/15\n",
      "13553/13553 [==============================] - 12s 855us/step - loss: 1.1469 - accuracy: 0.5417 - precision_11: 0.6131 - recall_11: 0.3194 - f1: 0.4111\n",
      "Epoch 2/15\n",
      "13553/13553 [==============================] - 12s 900us/step - loss: 1.0721 - accuracy: 0.5765 - precision_11: 0.6455 - recall_11: 0.4094 - f1: 0.4976\n",
      "Epoch 3/15\n",
      "13553/13553 [==============================] - 13s 941us/step - loss: 1.0413 - accuracy: 0.5849 - precision_11: 0.6559 - recall_11: 0.4420 - f1: 0.5256\n",
      "Epoch 4/15\n",
      "13553/13553 [==============================] - 13s 954us/step - loss: 1.0166 - accuracy: 0.5950 - precision_11: 0.6678 - recall_11: 0.4673 - f1: 0.5474\n",
      "Epoch 5/15\n",
      "13553/13553 [==============================] - 12s 892us/step - loss: 1.0006 - accuracy: 0.6050 - precision_11: 0.6755 - recall_11: 0.4809 - f1: 0.5598\n",
      "Epoch 6/15\n",
      "13553/13553 [==============================] - 12s 889us/step - loss: 0.9818 - accuracy: 0.6114 - precision_11: 0.6840 - recall_11: 0.4857 - f1: 0.5664\n",
      "Epoch 7/15\n",
      "13553/13553 [==============================] - 12s 912us/step - loss: 0.9668 - accuracy: 0.6178 - precision_11: 0.6953 - recall_11: 0.4958 - f1: 0.5768\n",
      "Epoch 8/15\n",
      "13553/13553 [==============================] - 13s 970us/step - loss: 0.9531 - accuracy: 0.6233 - precision_11: 0.6956 - recall_11: 0.5088 - f1: 0.5856\n",
      "Epoch 9/15\n",
      "13553/13553 [==============================] - 11s 841us/step - loss: 0.9428 - accuracy: 0.6278 - precision_11: 0.7023 - recall_11: 0.5149 - f1: 0.5924\n",
      "Epoch 10/15\n",
      "13553/13553 [==============================] - 12s 861us/step - loss: 0.9275 - accuracy: 0.6330 - precision_11: 0.7092 - recall_11: 0.5242 - f1: 0.6012\n",
      "Epoch 11/15\n",
      "13553/13553 [==============================] - 13s 963us/step - loss: 0.9114 - accuracy: 0.6372 - precision_11: 0.7181 - recall_11: 0.5271 - f1: 0.6059\n",
      "Epoch 12/15\n",
      "13553/13553 [==============================] - 12s 893us/step - loss: 0.9000 - accuracy: 0.6456 - precision_11: 0.7195 - recall_11: 0.5374 - f1: 0.6138\n",
      "Epoch 13/15\n",
      "13553/13553 [==============================] - 12s 896us/step - loss: 0.8910 - accuracy: 0.6486 - precision_11: 0.7246 - recall_11: 0.5419 - f1: 0.6182\n",
      "Epoch 14/15\n",
      "13553/13553 [==============================] - 12s 857us/step - loss: 0.8795 - accuracy: 0.6525 - precision_11: 0.7256 - recall_11: 0.5484 - f1: 0.6226\n",
      "Epoch 15/15\n",
      "13553/13553 [==============================] - 13s 957us/step - loss: 0.8644 - accuracy: 0.6593 - precision_11: 0.7315 - recall_11: 0.5583 - f1: 0.6318\n",
      "Score for fold 9:\n",
      "     loss of 1.0920236087731947; \n",
      "     accuracy of 59.22974944114685% ;\n",
      "     precision_11 of 64.8245632648468% ;\n",
      "     recall_11 of 49.070385098457336% ;\n",
      "     f1 of 55.61099648475647% ;\n",
      "     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lahiru/anaconda3/envs/LASER-tf-1/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(32, activation=\"relu\", name=\"mlp\", kernel_initializer=\"he_normal\", kernel_constraint=<keras.con..., bias_constraint=<keras.con...)`\n",
      "  del sys.path[0]\n",
      "/home/lahiru/anaconda3/envs/LASER-tf-1/lib/python3.6/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, activation=\"softmax\", name=\"output\", kernel_initializer=\"he_normal\")`\n",
      "/home/lahiru/anaconda3/envs/LASER-tf-1/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `Model` call to the Keras 2 API: `Model(name=\"RNN_model\", inputs=Tensor(\"ma..., outputs=Tensor(\"ou...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"RNN_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "main_input (InputLayer)      (None, 64, 16)            0         \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 32)                6272      \n",
      "_________________________________________________________________\n",
      "mlp (Dense)                  (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "drop (Dropout)               (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 7,460\n",
      "Trainable params: 7,460\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "Training and Testing...\n",
      "Epoch 1/15\n",
      "13554/13554 [==============================] - 12s 864us/step - loss: 1.1558 - accuracy: 0.5376 - precision_12: 0.6123 - recall_12: 0.3029 - f1: 0.3954\n",
      "Epoch 2/15\n",
      "13554/13554 [==============================] - 11s 837us/step - loss: 1.0700 - accuracy: 0.5775 - precision_12: 0.6443 - recall_12: 0.4103 - f1: 0.4981\n",
      "Epoch 3/15\n",
      "13554/13554 [==============================] - 12s 861us/step - loss: 1.0324 - accuracy: 0.5921 - precision_12: 0.6625 - recall_12: 0.4543 - f1: 0.5360\n",
      "Epoch 4/15\n",
      "13554/13554 [==============================] - 11s 835us/step - loss: 1.0083 - accuracy: 0.6009 - precision_12: 0.6679 - recall_12: 0.4768 - f1: 0.5545\n",
      "Epoch 5/15\n",
      "13554/13554 [==============================] - 11s 836us/step - loss: 0.9915 - accuracy: 0.6095 - precision_12: 0.6771 - recall_12: 0.4951 - f1: 0.5703\n",
      "Epoch 6/15\n",
      "13554/13554 [==============================] - 11s 837us/step - loss: 0.9750 - accuracy: 0.6197 - precision_12: 0.6837 - recall_12: 0.5128 - f1: 0.5842\n",
      "Epoch 7/15\n",
      "13554/13554 [==============================] - 11s 840us/step - loss: 0.9563 - accuracy: 0.6228 - precision_12: 0.6850 - recall_12: 0.5215 - f1: 0.5901\n",
      "Epoch 8/15\n",
      "13554/13554 [==============================] - 12s 864us/step - loss: 0.9465 - accuracy: 0.6291 - precision_12: 0.6871 - recall_12: 0.5255 - f1: 0.5937\n",
      "Epoch 9/15\n",
      "13554/13554 [==============================] - 12s 852us/step - loss: 0.9327 - accuracy: 0.6338 - precision_12: 0.6950 - recall_12: 0.5359 - f1: 0.6038\n",
      "Epoch 10/15\n",
      "13554/13554 [==============================] - 11s 844us/step - loss: 0.9224 - accuracy: 0.6381 - precision_12: 0.6958 - recall_12: 0.5418 - f1: 0.6079\n",
      "Epoch 11/15\n",
      "13554/13554 [==============================] - 11s 844us/step - loss: 0.9036 - accuracy: 0.6456 - precision_12: 0.7027 - recall_12: 0.5487 - f1: 0.6154\n",
      "Epoch 12/15\n",
      "13554/13554 [==============================] - 12s 851us/step - loss: 0.8940 - accuracy: 0.6479 - precision_12: 0.7031 - recall_12: 0.5566 - f1: 0.6196\n",
      "Epoch 13/15\n",
      "13554/13554 [==============================] - 11s 848us/step - loss: 0.8833 - accuracy: 0.6515 - precision_12: 0.7127 - recall_12: 0.5613 - f1: 0.6264\n",
      "Epoch 14/15\n",
      "13554/13554 [==============================] - 11s 848us/step - loss: 0.8718 - accuracy: 0.6552 - precision_12: 0.7144 - recall_12: 0.5604 - f1: 0.6268\n",
      "Epoch 15/15\n",
      "13554/13554 [==============================] - 12s 853us/step - loss: 0.8606 - accuracy: 0.6571 - precision_12: 0.7173 - recall_12: 0.5753 - f1: 0.6374\n",
      "Score for fold 10:\n",
      "     loss of 1.1690709002390256; \n",
      "     accuracy of 57.607972621917725% ;\n",
      "     precision_12 of 61.6460919380188% ;\n",
      "     recall_12 of 49.76744055747986% ;\n",
      "     f1 of 53.85386943817139% ;\n",
      "     \n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - \n",
      "    Loss: 1.1532501062232343 - \n",
      "    Accuracy: 0.5883134007453918% - \n",
      "    Precesion: 0.6296900510787964% - \n",
      "    Recall: 0.5126162171363831% - \n",
      "    F1: 0.5628028512001038%\n",
      "    \n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - \n",
      "    Loss: 1.0578877278374803 - \n",
      "    Accuracy: 0.6029216647148132% - \n",
      "    Precesion: 0.6554403901100159% - \n",
      "    Recall: 0.5039840340614319% - \n",
      "    F1: 0.566886842250824%\n",
      "    \n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - \n",
      "    Loss: 1.1079763001496414 - \n",
      "    Accuracy: 0.590969443321228% - \n",
      "    Precesion: 0.6314021944999695% - \n",
      "    Recall: 0.49933600425720215% - \n",
      "    F1: 0.5453005433082581%\n",
      "    \n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - \n",
      "    Loss: 1.0554572842510572 - \n",
      "    Accuracy: 0.616865873336792% - \n",
      "    Precesion: 0.6688796877861023% - \n",
      "    Recall: 0.5351925492286682% - \n",
      "    F1: 0.5922269821166992%\n",
      "    \n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - \n",
      "    Loss: 1.0784010602183551 - \n",
      "    Accuracy: 0.5936254858970642% - \n",
      "    Precesion: 0.6479400992393494% - \n",
      "    Recall: 0.4594953656196594% - \n",
      "    F1: 0.5259528756141663%\n",
      "    \n",
      "------------------------------------------------------------------------\n",
      "> Fold 6 - \n",
      "    Loss: 1.0389764961176817 - \n",
      "    Accuracy: 0.5976095795631409% - \n",
      "    Precesion: 0.6556939482688904% - \n",
      "    Recall: 0.4893758296966553% - \n",
      "    F1: 0.5671623349189758%\n",
      "    \n",
      "------------------------------------------------------------------------\n",
      "> Fold 7 - \n",
      "    Loss: 1.1758659440049455 - \n",
      "    Accuracy: 0.5869854092597961% - \n",
      "    Precesion: 0.6259168982505798% - \n",
      "    Recall: 0.5099601745605469% - \n",
      "    F1: 0.5576408505439758%\n",
      "    \n",
      "------------------------------------------------------------------------\n",
      "> Fold 8 - \n",
      "    Loss: 1.0591538824724802 - \n",
      "    Accuracy: 0.6035856604576111% - \n",
      "    Precesion: 0.6603284478187561% - \n",
      "    Recall: 0.5073041319847107% - \n",
      "    F1: 0.5742024779319763%\n",
      "    \n",
      "------------------------------------------------------------------------\n",
      "> Fold 9 - \n",
      "    Loss: 1.0920236087731947 - \n",
      "    Accuracy: 0.5922974944114685% - \n",
      "    Precesion: 0.648245632648468% - \n",
      "    Recall: 0.49070385098457336% - \n",
      "    F1: 0.5561099648475647%\n",
      "    \n",
      "------------------------------------------------------------------------\n",
      "> Fold 10 - \n",
      "    Loss: 1.1690709002390256 - \n",
      "    Accuracy: 0.5760797262191772% - \n",
      "    Precesion: 0.616460919380188% - \n",
      "    Recall: 0.4976744055747986% - \n",
      "    F1: 0.5385386943817139%\n",
      "    \n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Loss: 1.0988063310287095\n",
      "> Accuracy: 0.5949253737926483 (+- 0.01055318063807326)\n",
      "> Precision: 0.6439998269081115\n",
      "> Recall: 0.500564256310463\n",
      "> F1: 0.5586824417114258\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "Do_Cross_Validation(sinhala_std, y_sinhala)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
