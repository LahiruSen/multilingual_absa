{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import Counter, defaultdict\n",
    "import re\n",
    "\n",
    "pd.set_option('display.max_colwidth' , -1)\n",
    "\n",
    "import sys\n",
    "import re\n",
    "import os\n",
    "from pathlib import Path\n",
    "from collections import namedtuple\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 1708 reviews in this training set\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "english = ET.parse('../data/xml_files/English_restaurants.xml')\n",
    "root = english.getroot()\n",
    "labeled_reviews = []\n",
    "for review in root.findall(\"Review\"):\n",
    "    rid = review.get('rid')\n",
    "    if review.find(\"sentences\"):\n",
    "        for sentence in review.find(\"sentences\").findall('sentence'): \n",
    "            if sentence.find('Opinions'):\n",
    "                #print(sentence[0].text)\n",
    "                entry= {} ;   aspects = [] ;  polarities = []\n",
    "                for opinion in sentence.find('Opinions').findall('Opinion'):\n",
    "                    aspects.append(opinion.get('category'))\n",
    "                    polarities.append(opinion.get('polarity'))\n",
    "            \n",
    "                entry['review_id'] = rid#.copy()\n",
    "                entry[\"text\"] = sentence[0].text\n",
    "                entry[\"aspects\"] , entry['polarities']  =  aspects , polarities\n",
    "                labeled_reviews.append(entry)\n",
    "            \n",
    "eng_multi_aspects = pd.DataFrame(labeled_reviews)\n",
    "print(\"there are\",len(labeled_reviews),\"reviews in this training set\")\n",
    "\n",
    "#eng_multi_aspects.to_csv('../data/English_restaurants.csv' , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete_review = eng_multi_aspects.groupby(['review_id'])['text'].apply(lambda x: ' '.join(x) ).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>Z#7</td>\n",
       "      <td>This place doesn't make any sense Just want to warn you all - don't waste your time and money. This place has totally weird decor, stairs going up with mirrored walls - I am surprised how no one yet broke their head or fall off the stairs - mirrored walls make you dizzy and delusional... This place is not inviting and the food is totally weird. The concept of japanese tapas is newly created and clearly doesn't work. The food they serve is not comforting, not appetizing and uncooked.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>Z#9</td>\n",
       "      <td>short and sweet – seating is great:it's romantic,cozy and private. The boths are not as small as some of the reviews make them out to look they're perfect for 2 people. The service was extremely fast and attentive(thanks to the service button on your table) but I barely understood 1 word when the waiter took our order. The food was ok and fair nothing to go crazy. Over all the looks of the place exceeds the actual meals. So what you really end up paying for is the restaurant not the food. Will prob. not return but it is a great dinning experience to try atleast once.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    review_id  \\\n",
       "347  Z#7        \n",
       "348  Z#9        \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              text  \n",
       "347  This place doesn't make any sense Just want to warn you all - don't waste your time and money. This place has totally weird decor, stairs going up with mirrored walls - I am surprised how no one yet broke their head or fall off the stairs - mirrored walls make you dizzy and delusional... This place is not inviting and the food is totally weird. The concept of japanese tapas is newly created and clearly doesn't work. The food they serve is not comforting, not appetizing and uncooked.                                                                                        \n",
       "348  short and sweet – seating is great:it's romantic,cozy and private. The boths are not as small as some of the reviews make them out to look they're perfect for 2 people. The service was extremely fast and attentive(thanks to the service button on your table) but I barely understood 1 word when the waiter took our order. The food was ok and fair nothing to go crazy. Over all the looks of the place exceeds the actual meals. So what you really end up paying for is the restaurant not the food. Will prob. not return but it is a great dinning experience to try atleast once.  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_complete_review.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #from neuralcoref import Coref\n",
    "# import en_core_web_sm\n",
    "# spacy = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz#egg=en_core_web_sm==2.1.0 in /home/FRACTAL/swati.tiwari/anaconda3/envs/fastai38/lib/python3.7/site-packages (2.1.0)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "! python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/FRACTAL/swati.tiwari/anaconda3/envs/fastai38/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: spacy.tokens.span.Span size changed, may indicate binary incompatibility. Expected 72 from C header, got 80 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import neuralcoref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import spacy#en_core_web_sm\n",
    "nlp = spacy.load('en_core_web_sm')#en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuralcoref.add_to_pipe(nlp)\n",
    "\n",
    "def replace_pronouns(text):\n",
    "    result = doc._.coref_resolved  \n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'My sister has a dog. She loves him.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation) \n",
    "lemma = WordNetLemmatizer()\n",
    "def clean(doc):\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    return normalized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_complete = df_complete_review['text'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_clean = [clean(doc).split() for doc in doc_complete]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['short', 'sweet', '–', 'seating', 'greatits']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_clean[-1][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(doc_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "ldamodel = Lda(doc_term_matrix, num_topics=5, id2word = dictionary, passes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.017*\"food\" + 0.016*\"great\" + 0.012*\"good\" + 0.012*\"service\" + 0.011*\"restaurant\" + 0.011*\"place\" + 0.006*\"wine\" + 0.006*\"price\" + 0.005*\"one\" + 0.005*\"best\"'), (1, '0.017*\"food\" + 0.015*\"service\" + 0.010*\"good\" + 0.007*\"it\" + 0.006*\"place\" + 0.006*\"get\" + 0.006*\"go\" + 0.005*\"worth\" + 0.004*\"atmosphere\" + 0.004*\"dinner\"'), (2, '0.019*\"food\" + 0.017*\"great\" + 0.014*\"service\" + 0.012*\"restaurant\" + 0.011*\"place\" + 0.010*\"sushi\" + 0.009*\"go\" + 0.008*\"time\" + 0.008*\"good\" + 0.006*\"like\"'), (3, '0.020*\"place\" + 0.020*\"food\" + 0.016*\"good\" + 0.011*\"great\" + 0.010*\"pizza\" + 0.008*\"best\" + 0.008*\"go\" + 0.008*\"service\" + 0.006*\"would\" + 0.006*\"back\"'), (4, '0.022*\"food\" + 0.015*\"place\" + 0.012*\"great\" + 0.011*\"good\" + 0.008*\"service\" + 0.007*\"time\" + 0.007*\"it\" + 0.006*\"like\" + 0.006*\"drink\" + 0.006*\"price\"')]\n"
     ]
    }
   ],
   "source": [
    "print(ldamodel.print_topics(num_topics=5, num_words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#restaurant_data = pd.read_csv('/home/FRACTAL/swati.tiwari/kaggle/yelp/Unsupervised-Aspect-Extraction-master/datasets/restaurant_old/train.txt' , header = None , sep =' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_data = '/home/FRACTAL/swati.tiwari/kaggle/yelp/Unsupervised-Aspect-Extraction-master/datasets/restaurant_old/train.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(restaurant_data , 'r')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_280k = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We waited over an hour and were eventually seated at folding tables with vinyl table cloths and folding chairs\\n'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest_280k[210]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_clean = [clean(doc).split() for doc in rest_280k]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['waited',\n",
       " 'hour',\n",
       " 'eventually',\n",
       " 'seated',\n",
       " 'folding',\n",
       " 'table',\n",
       " 'vinyl',\n",
       " 'table',\n",
       " 'cloth',\n",
       " 'folding',\n",
       " 'chair']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_clean[210]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(doc_clean)\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "ldamodel = Lda(doc_term_matrix, num_topics=5, id2word = dictionary, passes=300,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.022*\"time\" + 0.020*\"u\" + 0.018*\"table\" + 0.015*\"waiter\" + 0.015*\"went\" + 0.014*\"night\" + 0.013*\"get\" + 0.012*\"dinner\" + 0.011*\"order\" + 0.010*\"wait\" + 0.009*\"friend\" + 0.008*\"even\" + 0.008*\"reservation\" + 0.008*\"minute\" + 0.007*\"came\" + 0.007*\"got\" + 0.007*\"two\" + 0.007*\"last\" + 0.007*\"pasta\" + 0.007*\"seated\"'), (1, '0.025*\"pizza\" + 0.016*\"steak\" + 0.015*\"fresh\" + 0.014*\"chicken\" + 0.011*\"sauce\" + 0.011*\"salad\" + 0.011*\"dish\" + 0.009*\"like\" + 0.009*\"best\" + 0.009*\"good\" + 0.008*\"delicious\" + 0.008*\"cheese\" + 0.007*\"try\" + 0.007*\"fish\" + 0.007*\"burger\" + 0.006*\"side\" + 0.006*\"meat\" + 0.006*\"also\" + 0.006*\"ordered\" + 0.006*\"disappointed\"'), (2, '0.039*\"food\" + 0.027*\"good\" + 0.025*\"menu\" + 0.021*\"really\" + 0.019*\"wine\" + 0.012*\"well\" + 0.010*\"portion\" + 0.010*\"everything\" + 0.009*\"dessert\" + 0.009*\"special\" + 0.008*\"tasty\" + 0.008*\"nothing\" + 0.008*\"price\" + 0.008*\"dish\" + 0.007*\"selection\" + 0.006*\"also\" + 0.006*\"list\" + 0.006*\"worth\" + 0.006*\"delicious\" + 0.006*\"diner\"'), (3, '0.060*\"food\" + 0.053*\"great\" + 0.044*\"service\" + 0.033*\"place\" + 0.025*\"good\" + 0.017*\"back\" + 0.013*\"friendly\" + 0.012*\"price\" + 0.012*\"restaurant\" + 0.011*\"nice\" + 0.011*\"atmosphere\" + 0.010*\"staff\" + 0.010*\"recommend\" + 0.010*\"go\" + 0.009*\"always\" + 0.008*\"definitely\" + 0.008*\"excellent\" + 0.007*\"would\" + 0.007*\"experience\" + 0.007*\"room\"'), (4, '0.025*\"place\" + 0.023*\"restaurant\" + 0.021*\"best\" + 0.018*\"one\" + 0.017*\"go\" + 0.017*\"like\" + 0.014*\"ive\" + 0.012*\"better\" + 0.010*\"new\" + 0.010*\"time\" + 0.010*\"get\" + 0.010*\"eat\" + 0.009*\"never\" + 0.008*\"make\" + 0.008*\"many\" + 0.008*\"try\" + 0.008*\"know\" + 0.008*\"city\" + 0.007*\"much\" + 0.007*\"year\"')]\n"
     ]
    }
   ],
   "source": [
    "print(ldamodel.print_topics(num_topics=5, num_words=20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
