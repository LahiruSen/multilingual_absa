{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import os\n",
    "from pathlib import Path\n",
    "from collections import namedtuple\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking data set from Seeval 2016 - task 5 subset 1 : http://alt.qcri.org/semeval2016/task5/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import Counter, defaultdict\n",
    "import re\n",
    "\n",
    "pd.set_option('display.max_colwidth' , -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English - Restaurant domain training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/ABSA16_Restaurants_Train_SB1_v2.xml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5c2299cc74fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0metree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mElementTree\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mET\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0menglish\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mET\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/ABSA16_Restaurants_Train_SB1_v2.xml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menglish\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetroot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai38/lib/python3.7/xml/etree/ElementTree.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(source, parser)\u001b[0m\n\u001b[1;32m   1195\u001b[0m     \"\"\"\n\u001b[1;32m   1196\u001b[0m     \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mElementTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1197\u001b[0;31m     \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1198\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai38/lib/python3.7/xml/etree/ElementTree.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, source, parser)\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[0mclose_source\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m             \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m             \u001b[0mclose_source\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/ABSA16_Restaurants_Train_SB1_v2.xml'"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "english = ET.parse('../data/ABSA16_Restaurants_Train_SB1_v2.xml')\n",
    "root = english.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'root' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-fbadb011a4eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlabeled_reviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mreview\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Review\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sentences\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'root' is not defined"
     ]
    }
   ],
   "source": [
    "labeled_reviews = []\n",
    "for review in root.findall(\"Review\"):\n",
    " \n",
    "\n",
    "    if review.find(\"sentences\"):\n",
    "        \n",
    "        for sentence in review.find(\"sentences\").findall('sentence'): \n",
    "            if sentence.find('Opinions'):\n",
    "                #print(sentence[0].text)\n",
    "                entry= {} ;   aspects = [] ;  polarities = []\n",
    "                for opinion in sentence.find('Opinions').findall('Opinion'):\n",
    "                    aspects.append(opinion.get('category'))\n",
    "                    polarities.append(opinion.get('polarity'))\n",
    "\n",
    "        \n",
    "    \n",
    "                entry[\"text\"] = sentence[0].text\n",
    "                entry[\"aspects\"] , entry['polarities']  =  aspects , polarities\n",
    "                labeled_reviews.append(entry)\n",
    "            \n",
    "eng_multi_aspects = pd.DataFrame(labeled_reviews)\n",
    "print(\"there are\",len(labeled_reviews),\"reviews in this training set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aspects</th>\n",
       "      <th>polarities</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[RESTAURANT#GENERAL]</td>\n",
       "      <td>[negative]</td>\n",
       "      <td>Judging from previous posts this used to be a good place, but not any longer.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[SERVICE#GENERAL]</td>\n",
       "      <td>[negative]</td>\n",
       "      <td>We, there were four of us, arrived at noon - the place was empty - and the staff acted like we were imposing on them and they were very rude.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[SERVICE#GENERAL]</td>\n",
       "      <td>[negative]</td>\n",
       "      <td>They never brought us complimentary noodles, ignored repeated requests for sugar, and threw our dishes on the table.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[FOOD#QUALITY, FOOD#STYLE_OPTIONS]</td>\n",
       "      <td>[negative, negative]</td>\n",
       "      <td>The food was lousy - too sweet or too salty and the portions tiny.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[SERVICE#GENERAL]</td>\n",
       "      <td>[negative]</td>\n",
       "      <td>After all that, they complained to me about the small tip.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              aspects            polarities  \\\n",
       "0  [RESTAURANT#GENERAL]                [negative]             \n",
       "1  [SERVICE#GENERAL]                   [negative]             \n",
       "2  [SERVICE#GENERAL]                   [negative]             \n",
       "3  [FOOD#QUALITY, FOOD#STYLE_OPTIONS]  [negative, negative]   \n",
       "4  [SERVICE#GENERAL]                   [negative]             \n",
       "\n",
       "                                                                                                                                            text  \n",
       "0  Judging from previous posts this used to be a good place, but not any longer.                                                                  \n",
       "1  We, there were four of us, arrived at noon - the place was empty - and the staff acted like we were imposing on them and they were very rude.  \n",
       "2  They never brought us complimentary noodles, ignored repeated requests for sugar, and threw our dishes on the table.                           \n",
       "3  The food was lousy - too sweet or too salty and the portions tiny.                                                                             \n",
       "4  After all that, they complained to me about the small tip.                                                                                     "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_multi_aspects.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dutch  - Restaurant domain training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 1317 reviews in this training set\n"
     ]
    }
   ],
   "source": [
    "english = ET.parse('../data/restaurants_dutch_training.xml')\n",
    "root = english.getroot()\n",
    "\n",
    "labeled_reviews = []\n",
    "for review in root.findall(\"Review\"):\n",
    " \n",
    "\n",
    "    if review.find(\"sentences\"):\n",
    "        \n",
    "        for sentence in review.find(\"sentences\").findall('sentence'): \n",
    "            if sentence.find('Opinions'):\n",
    "                #print(sentence[0].text)\n",
    "                entry= {} ;   aspects = [] ;  polarities = []\n",
    "                for opinion in sentence.find('Opinions').findall('Opinion'):\n",
    "                    aspects.append(opinion.get('category'))\n",
    "                    polarities.append(opinion.get('polarity'))\n",
    "\n",
    "        \n",
    "    \n",
    "                entry[\"text\"] = sentence[0].text\n",
    "                entry[\"aspects\"] , entry['polarities']  =  aspects , polarities\n",
    "                labeled_reviews.append(entry)\n",
    "            \n",
    "du_multi_aspects = pd.DataFrame(labeled_reviews)\n",
    "print(\"there are\",len(labeled_reviews),\"reviews in this training set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aspects</th>\n",
       "      <th>polarities</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[SERVICE#GENERAL]</td>\n",
       "      <td>[negative]</td>\n",
       "      <td>Lange wachttijd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[FOOD#STYLE_OPTIONS]</td>\n",
       "      <td>[negative]</td>\n",
       "      <td>Zelfde dessert, 2 dagen na mekaar.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[FOOD#QUALITY]</td>\n",
       "      <td>[positive]</td>\n",
       "      <td>Ontbijtbuffet was tip top in orde.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[RESTAURANT#PRICES]</td>\n",
       "      <td>[negative]</td>\n",
       "      <td>Niet goedkoop!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[RESTAURANT#GENERAL]</td>\n",
       "      <td>[positive]</td>\n",
       "      <td>Maar eens in het kasteelrestaurant aangekomen werd het een feest.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                aspects  polarities  \\\n",
       "0  [SERVICE#GENERAL]     [negative]   \n",
       "1  [FOOD#STYLE_OPTIONS]  [negative]   \n",
       "2  [FOOD#QUALITY]        [positive]   \n",
       "3  [RESTAURANT#PRICES]   [negative]   \n",
       "4  [RESTAURANT#GENERAL]  [positive]   \n",
       "\n",
       "                                                                text  \n",
       "0  Lange wachttijd.                                                   \n",
       "1  Zelfde dessert, 2 dagen na mekaar.                                 \n",
       "2  Ontbijtbuffet was tip top in orde.                                 \n",
       "3  Niet goedkoop!                                                     \n",
       "4  Maar eens in het kasteelrestaurant aangekomen werd het een feest.  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "du_multi_aspects.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will extract embeddings for text column using https://github.com/facebookresearch/LASER . Saving text column separately for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_multi_aspects[['text']].to_csv('../data/tatoeba/v1/english_resturant.txt' , header = None , index = None , mode = 'a')\n",
    "du_multi_aspects[['text']].to_csv('../data/tatoeba/v1/dutch_resturant.txt' , header = None , index = None , mode = 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LASER_PATH = \"..\"\n",
    "sys.path.append(LASER_PATH + '/source')\n",
    "sys.path.append(LASER_PATH + '/source/lib')\n",
    "\n",
    "DATA_PATH = Path(\"../data/tatoeba/v1/\")\n",
    "CACHE_PATH = Path(\"cache/\")\n",
    "CACHE_PATH.mkdir(exist_ok=True)\n",
    "MODEL_PATH = Path(\"../models\")\n",
    "\n",
    "os.environ[\"LASER\"] = LASER_PATH "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPACE_NORMALIZER = re.compile(\"\\s+\")\n",
    "Batch = namedtuple('Batch', 'srcs tokens lengths')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from indexing import IndexLoad, IndexTextOpen, IndexTextQuery, IndexSearchKNN, IndexCreate, IndexSearchMultiple\n",
    "from embed import SentenceEncoder, EncodeLoad, EncodeFile\n",
    "from text_processing import Token, BPEfastApply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Following steps from https://medium.com/the-artificial-impostor/multilingual-similarity-search-using-pretrained-bidirectional-lstm-encoder-e34fac5958b0 for tokenization , BPE Fast and Embedding extractions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Tokenizer: english_resturant.txt exists already\n"
     ]
    }
   ],
   "source": [
    "Token(\n",
    "    str(DATA_PATH / \"english_resturant.txt\"),\n",
    "    str(CACHE_PATH / \"english_resturant.txt\"),\n",
    "    lang=\"eng\",\n",
    "    romanize=False,\n",
    "    lower_case=True, gzip=False,\n",
    "    verbose=True, over_write=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Tokenizer: dutch_resturant.txt exists already\n"
     ]
    }
   ],
   "source": [
    "Token(\n",
    "    str(DATA_PATH / \"dutch_resturant.txt\"),\n",
    "    str(CACHE_PATH / \"dutch_resturant.txt\"),\n",
    "    lang=\"nld\",\n",
    "    romanize=False,\n",
    "    lower_case=True, gzip=False,\n",
    "    verbose=True, over_write=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - fast BPE: english_resturant.txt.bpe exists already\n"
     ]
    }
   ],
   "source": [
    "bpe_codes = str(MODEL_PATH / \"93langs.fcodes\")\n",
    "BPEfastApply(\n",
    "    str(CACHE_PATH / \"english_resturant.txt\"),\n",
    "    str(CACHE_PATH / \"english_resturant.txt.bpe\"),\n",
    "    bpe_codes,\n",
    "    verbose=True, over_write=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - fast BPE: dutch_resturant.txt.bpe exists already\n"
     ]
    }
   ],
   "source": [
    "BPEfastApply(\n",
    "    str(CACHE_PATH / \"dutch_resturant.txt\"),\n",
    "    str(CACHE_PATH / \"dutch_resturant.txt.bpe\"),\n",
    "    bpe_codes,\n",
    "    verbose=True, over_write=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Setence Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = SentenceEncoder(\n",
    "    str(MODEL_PATH / \"bilstm.93langs.2018-12-26.pt\"),\n",
    "    max_sentences=None,\n",
    "    max_tokens=10000,\n",
    "    cpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Encoder: dutch_resturant.txt.enc exists already\n"
     ]
    }
   ],
   "source": [
    "EncodeFile(\n",
    "    encoder,\n",
    "    str(CACHE_PATH / \"dutch_resturant.txt.bpe\"),\n",
    "    str(CACHE_PATH / \"dutch_resturant.txt.enc\"),\n",
    "    verbose=True, over_write=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Encoder: english_resturant.txt.enc exists already\n"
     ]
    }
   ],
   "source": [
    "EncodeFile(\n",
    "    encoder,\n",
    "    str(CACHE_PATH / \"english_resturant.txt.bpe\"),\n",
    "    str(CACHE_PATH / \"english_resturant.txt.enc\"),\n",
    "    verbose=True, over_write=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - embedding: cache/english_resturant.txt.enc 1708 examples of dim 1024\n",
      " - creating FAISS index\n",
      " - embedding: cache/dutch_resturant.txt.enc 1317 examples of dim 1024\n",
      " - creating FAISS index\n"
     ]
    }
   ],
   "source": [
    "data_en, index_en = IndexCreate(\n",
    "    str(CACHE_PATH / \"english_resturant.txt.enc\"), 'FlatL2', verbose=True, save_index=False)\n",
    "data_du, index_du = IndexCreate(\n",
    "    str(CACHE_PATH / \"dutch_resturant.txt.enc\"), 'FlatL2', verbose=True, save_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will search 3 nearest neighbour of 10  dutch sentences in all 1700 english sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, matched_indices = index_en.search(data_du, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1708"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "du_list =  np.array(du_multi_aspects[['text']].head(10))\n",
    "eng_list = np.array(eng_multi_aspects[['text']])\n",
    "len(eng_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dutch:    ['Lange wachttijd.']\n",
      "Predict(1): ['Great staff.']\n",
      "Predict(2): ['Great survice']\n",
      "Predict(3): ['Beautiful experience.']\n",
      "\n",
      "Dutch:    ['Zelfde dessert, 2 dagen na mekaar.']\n",
      "Predict(1): ['Dessert: pure disaster.']\n",
      "Predict(2): ['The entree was bland and small, dessert was not inspired.']\n",
      "Predict(3): ['We thought the dessert would be better, Wrong!']\n",
      "\n",
      "Dutch:    ['Ontbijtbuffet was tip top in orde.']\n",
      "Predict(1): ['fine dining restaurant quality.']\n",
      "Predict(2): ['The buffet had a nice selection.']\n",
      "Predict(3): ['Wine list selection is good and wine-by-the-glass was generously filled to the top.']\n",
      "\n",
      "Dutch:    ['Niet goedkoop!']\n",
      "Predict(1): ['Also very inexpensive.']\n",
      "Predict(2): ['And amazingly cheap.']\n",
      "Predict(3): ['Not worth it.']\n",
      "\n",
      "Dutch:    ['Maar eens in het kasteelrestaurant aangekomen werd het een feest.']\n",
      "Predict(1): ['After really enjoying ourselves at the bar we sat down at a table and had dinner.']\n",
      "Predict(2): ['I attended a holiday dinner at the restaurant, and the food was majorly disappointing.']\n",
      "Predict(3): ['We had the lobster sandwich and it was FANTASTIC.']\n",
      "\n",
      "Dutch:    ['Vooreerst de bediening, uitzonderlijk vriendelijk attent niet geforceerd maar echt.']\n",
      "Predict(1): ['Service was very good - prompt, attentive and non-intrusive.']\n",
      "Predict(2): ['The food was amazing, and the service was prompt and helpful, but not over-bearing or rushed.']\n",
      "Predict(3): ['The service was attentive, yet discreet.']\n",
      "\n",
      "Dutch:    ['Zelden meegemaakt, tussen het personeel was er een heerlijk plagende chemie.']\n",
      "Predict(1): ['Both times I was extremely dissappointed by the service, which was boarderline rude.']\n",
      "Predict(2): ['The staff was accomodating, the food was absolutely delicious and the place is lovely.']\n",
      "Predict(3): ['Nice atmosphere, the service was very pleasant and the desert was good.']\n",
      "\n",
      "Dutch:    ['Je hebt de keuze tussen een beperkt aantal menus.']\n",
      "Predict(1): ['The menu is fairly simple without much descriptions. ']\n",
      "Predict(2): ['The menu is limited but almost all of the dishes are excellent.']\n",
      "Predict(3): ['this little place has a cute interior decor and affordable city prices.']\n",
      "\n",
      "Dutch:    ['Als je uitleg vraagt over dit lekkere rundvlees wordt het vlees op voorhand op een bord aan je voorgesteld.']\n",
      "Predict(1): ['The exotic food is beautifully presented and is a delight in delicious combinations.']\n",
      "Predict(2): ['Wine list selection is good and wine-by-the-glass was generously filled to the top.']\n",
      "Predict(3): ['The have over 100 different beers to offer thier guest so that made my husband very happy and the food was delicious, if I must recommend a dish it must be the pumkin tortelini.']\n",
      "\n",
      "Dutch:    ['Goedkoop is het niet maar wel uitzonderlijk lekker.']\n",
      "Predict(1): ['Food is great and inexpensive.']\n",
      "Predict(2): ['It is very overpriced and not very tasty.']\n",
      "Predict(3): ['The restaurant is cute but not upscale.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top1_correct, top3_correct = 0, 0\n",
    "for i, ztitle in enumerate(du_list):\n",
    "    print(\n",
    "        \"Dutch:    \", ztitle, \"\\n\",\n",
    "        #\"Correct:    \", translated_titles[i], \"\\n\",\n",
    "        \"Predict(1): \", eng_list[matched_indices[i, 0]], \"\\n\",\n",
    "        \"Predict(2): \", eng_list[matched_indices[i, 1]], \"\\n\",\n",
    "        \"Predict(3): \", eng_list[matched_indices[i, 2]], \"\\n\",\n",
    "        sep=\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Because dataset of semeval is not exact translation of each other , some of the above results are not good. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating multi label classification task using LASER sentence embedding. \n",
    "We can have 6 aspect categories , present for each review. We will train a simple 1 layer Neural Network model using 1024 dimensional sentence embedding as input and 6 categories as output.  \n",
    "Train the model on 1700 English sentences and Validate on 1300 Dutch sentences . We are getting around 85 % accuracy and 57% f1 score(Macro) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_aspects(lst_aspects):\n",
    "    res = []\n",
    "    for x in lst_aspects:\n",
    "        res.append(x.split('#')[0])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_multi_aspects['aspects2'] = eng_multi_aspects['aspects'].apply(lambda x: extract_aspects(x))\n",
    "eng_multi_aspects['aspects2'] = eng_multi_aspects['aspects2'].apply(lambda x : list(set(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using only entity part out of entity#attribute tuple for simlicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aspects</th>\n",
       "      <th>polarities</th>\n",
       "      <th>text</th>\n",
       "      <th>aspects2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[RESTAURANT#GENERAL]</td>\n",
       "      <td>[negative]</td>\n",
       "      <td>Judging from previous posts this used to be a good place, but not any longer.</td>\n",
       "      <td>[RESTAURANT]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[SERVICE#GENERAL]</td>\n",
       "      <td>[negative]</td>\n",
       "      <td>We, there were four of us, arrived at noon - the place was empty - and the staff acted like we were imposing on them and they were very rude.</td>\n",
       "      <td>[SERVICE]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                aspects  polarities  \\\n",
       "0  [RESTAURANT#GENERAL]  [negative]   \n",
       "1  [SERVICE#GENERAL]     [negative]   \n",
       "\n",
       "                                                                                                                                            text  \\\n",
       "0  Judging from previous posts this used to be a good place, but not any longer.                                                                   \n",
       "1  We, there were four of us, arrived at noon - the place was empty - and the staff acted like we were imposing on them and they were very rude.   \n",
       "\n",
       "       aspects2  \n",
       "0  [RESTAURANT]  \n",
       "1  [SERVICE]     "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_multi_aspects.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FOOD          757\n",
       "RESTAURANT    564\n",
       "SERVICE       419\n",
       "AMBIENCE      226\n",
       "DRINKS        79 \n",
       "LOCATION      28 \n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_multi_aspects.aspects2.apply(pd.Series).merge(eng_multi_aspects , right_index = True , left_index = True)\\\n",
    ".drop(['aspects' , 'polarities' , 'aspects2'] ,axis = 1)\\\n",
    ".melt(id_vars = ['text']).drop(['variable'] , axis = 1).dropna().value.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "du_multi_aspects['aspects2'] = du_multi_aspects['aspects'].apply(lambda x: extract_aspects(x))\n",
    "du_multi_aspects['aspects2'] = du_multi_aspects['aspects2'].apply(lambda x : list(set(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aspects</th>\n",
       "      <th>polarities</th>\n",
       "      <th>text</th>\n",
       "      <th>aspects2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[SERVICE#GENERAL]</td>\n",
       "      <td>[negative]</td>\n",
       "      <td>Lange wachttijd.</td>\n",
       "      <td>[SERVICE]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[FOOD#STYLE_OPTIONS]</td>\n",
       "      <td>[negative]</td>\n",
       "      <td>Zelfde dessert, 2 dagen na mekaar.</td>\n",
       "      <td>[FOOD]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                aspects  polarities                                text  \\\n",
       "0  [SERVICE#GENERAL]     [negative]  Lange wachttijd.                     \n",
       "1  [FOOD#STYLE_OPTIONS]  [negative]  Zelfde dessert, 2 dagen na mekaar.   \n",
       "\n",
       "    aspects2  \n",
       "0  [SERVICE]  \n",
       "1  [FOOD]     "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "du_multi_aspects.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FOOD          547\n",
       "SERVICE       420\n",
       "RESTAURANT    353\n",
       "AMBIENCE      178\n",
       "DRINKS        92 \n",
       "LOCATION      27 \n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "du_multi_aspects.aspects2.apply(pd.Series).merge(du_multi_aspects , right_index = True , left_index = True)\\\n",
    ".drop(['aspects' , 'polarities' , 'aspects2'] ,axis = 1)\\\n",
    ".melt(id_vars = ['text']).drop(['variable'] , axis = 1).dropna().value.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_multi_aspects.drop(columns=['aspects' , 'polarities'] , inplace=True)\n",
    "du_multi_aspects.drop(columns=['aspects' , 'polarities'] , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb  = MultiLabelBinarizer()\n",
    "y_eng = mlb.fit_transform(eng_multi_aspects.aspects2)\n",
    "y_du  = mlb.fit_transform(du_multi_aspects.aspects2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AMBIENCE', 'DRINKS', 'FOOD', 'LOCATION', 'RESTAURANT', 'SERVICE'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 1, 0]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_du[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "##One layer neural network with ReLU activation\n",
    "n_in, n_h, n_out, batch_size = 1024,  500 , 6, 64\n",
    "\n",
    "model = nn.Sequential(nn.Linear(n_in, n_h),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(n_h, n_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "x_train,y_train,x_valid,y_valid = map(torch.FloatTensor, (data_en,y_eng, data_du,y_du))\n",
    "n,c = x_train.shape\n",
    "y_train = y_train.type(torch.FloatTensor)\n",
    "y_valid = y_valid.type(torch.FloatTensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1708, 6]) torch.Size([1317, 6])\n",
      "torch.Size([1708, 1024]) torch.Size([1317, 1024])\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape , y_valid.shape)\n",
    "print(x_train.shape , x_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size , shuffle=True)\n",
    "\n",
    "valid_ds = TensorDataset(x_valid, y_valid )\n",
    "valid_dl = DataLoader(valid_ds , batch_size= batch_size )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrappedDataLoader():\n",
    "    def __init__(self, dl, func):\n",
    "        self.dl = dl\n",
    "        self.func = func\n",
    "        \n",
    "    def __len__(self): return len(self.dl)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        batches = iter(self.dl)\n",
    "        for b in batches: yield(self.func(*b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "def preprocess(x,y): return x.to(dev),y.to(dev)\n",
    "\n",
    "train_dl = WrappedDataLoader(train_dl, preprocess)\n",
    "valid_dl = WrappedDataLoader(valid_dl, preprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "optimizer = optim.Adam(model.parameters() , lr = 1e-2)\n",
    "loss_func = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(dev)\n",
    "loss_func = loss_func.to(dev)\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    acc = torch.sum(rounded_preds == y).float() \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0    \n",
    "    model.train()\n",
    "    ct = 0\n",
    "    for x, y in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        #text, text_lengths =x\n",
    "        predictions = model(x)\n",
    "        loss = criterion(predictions, y)\n",
    "        acc = binary_accuracy(predictions, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        ct = ct + x.shape[0]   \n",
    "    return epoch_loss / len(iterator), epoch_acc / (ct*6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0 \n",
    "    ct = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x ,y  in iterator:\n",
    "\n",
    "            predictions = model(x)#.squeeze(1)\n",
    "            loss = criterion(predictions,y)\n",
    "            acc = binary_accuracy(predictions, y)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            ct = ct + x.shape[0]\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / (ct*6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02\n",
      "\tTrain Loss: 0.408 | Train Acc: 81.40%\n",
      "\t Val. Loss: 0.358 |  Val. Acc: 85.71%\n",
      "Epoch: 03\n",
      "\tTrain Loss: 0.264 | Train Acc: 89.51%\n",
      "\t Val. Loss: 0.291 |  Val. Acc: 87.55%\n",
      "Epoch: 04\n",
      "\tTrain Loss: 0.199 | Train Acc: 92.21%\n",
      "\t Val. Loss: 0.265 |  Val. Acc: 88.88%\n",
      "Epoch: 05\n",
      "\tTrain Loss: 0.157 | Train Acc: 94.02%\n",
      "\t Val. Loss: 0.266 |  Val. Acc: 88.98%\n",
      "Epoch: 06\n",
      "\tTrain Loss: 0.131 | Train Acc: 94.76%\n",
      "\t Val. Loss: 0.272 |  Val. Acc: 88.88%\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "best_epoch = 0\n",
    "        \n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss , train_acc = train_model(model, train_dl, optimizer, loss_func)\n",
    "    valid_loss , valid_acc = validate_model(model, valid_dl, loss_func)\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        best_epoch = epoch\n",
    "        #print(f'Best validation loss!! {best_valid_loss}')\n",
    "        #torch.save(model.state_dict(), 'aspect_category.pt')\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02}')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = []\n",
    "text_data = []\n",
    "true_label = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for x ,y  in valid_dl:\n",
    "        predictions = model(x)#.squeeze(1)\n",
    "        rounded_preds = torch.round(torch.sigmoid(predictions))  #torch.round\n",
    "        preds = rounded_preds.data.cpu().numpy()\n",
    "        test_preds.append(preds)\n",
    "        true_label.append(y.data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspects = mlb.classes_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Merging prediction value with original test data and observe the metrics on overall level\n",
    "\"\"\"\n",
    "dutch_pred = pd.DataFrame(np.vstack(test_preds) ,index=du_multi_aspects.index , columns= [a+'_pred' for a in aspects])\n",
    "dutch_pred = pd.merge(du_multi_aspects, dutch_pred , left_index=True ,right_index = True)\n",
    "\n",
    "from sklearn.metrics import f1_score , confusion_matrix , accuracy_score , precision_score , recall_score , roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score 0.5785150146523276\n",
      "Accuracy score 0.8887623386484435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/FRACTAL/swati.tiwari/anaconda3/envs/fastai38/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/FRACTAL/swati.tiwari/anaconda3/envs/fastai38/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/FRACTAL/swati.tiwari/anaconda3/envs/fastai38/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(\"F1 score\",f1_score(y_du , dutch_pred[dutch_pred.columns[-6:]].as_matrix() , average='macro' ))\n",
    "print(\"Accuracy score\" , np.mean(y_du == dutch_pred[dutch_pred.columns[-6:]].as_matrix()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>aspects2</th>\n",
       "      <th>AMBIENCE_pred</th>\n",
       "      <th>DRINKS_pred</th>\n",
       "      <th>FOOD_pred</th>\n",
       "      <th>LOCATION_pred</th>\n",
       "      <th>RESTAURANT_pred</th>\n",
       "      <th>SERVICE_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>Niet goedkoop maar zeker zijn geld waard.</td>\n",
       "      <td>[RESTAURANT]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>Zeer goede wijnen.</td>\n",
       "      <td>[DRINKS]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>wij zijn hier een paar keer per jaar, en steeds slaagt men erin te verrassen.</td>\n",
       "      <td>[RESTAURANT]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>In de eerste plaats de creatieve gerechten en steeds terugkerend de top service.</td>\n",
       "      <td>[FOOD, SERVICE]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>Een vaste waarde op topniveau</td>\n",
       "      <td>[RESTAURANT]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                  text  \\\n",
       "1312  Niet goedkoop maar zeker zijn geld waard.                                          \n",
       "1313  Zeer goede wijnen.                                                                 \n",
       "1314  wij zijn hier een paar keer per jaar, en steeds slaagt men erin te verrassen.      \n",
       "1315  In de eerste plaats de creatieve gerechten en steeds terugkerend de top service.   \n",
       "1316  Een vaste waarde op topniveau                                                      \n",
       "\n",
       "             aspects2  AMBIENCE_pred  DRINKS_pred  FOOD_pred  LOCATION_pred  \\\n",
       "1312  [RESTAURANT]     0.0            0.0          1.0        0.0             \n",
       "1313  [DRINKS]         0.0            1.0          0.0        0.0             \n",
       "1314  [RESTAURANT]     0.0            0.0          0.0        0.0             \n",
       "1315  [FOOD, SERVICE]  0.0            0.0          0.0        0.0             \n",
       "1316  [RESTAURANT]     0.0            0.0          0.0        0.0             \n",
       "\n",
       "      RESTAURANT_pred  SERVICE_pred  \n",
       "1312  1.0              0.0           \n",
       "1313  0.0              0.0           \n",
       "1314  1.0              0.0           \n",
       "1315  0.0              1.0           \n",
       "1316  1.0              0.0           "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dutch_pred.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
